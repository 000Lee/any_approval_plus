{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actionLogType / type ë¶ˆì¼ì¹˜ ê²€ì¦ (ì‹œê°„ ë¹„êµ ì¶”ê°€)\n",
    "documents.activitiesì™€ approval_data_XXXX í…Œì´ë¸” ë¹„êµ\n",
    "\n",
    "**ë³€ê²½ì‚¬í•­**: ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ê²½ìš°, ì‹œê°„ê¹Œì§€ ë¹„êµí•˜ì—¬ ì •í™•íˆ 1:1 ë§¤ì¹­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# DB ì„¤ì •\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'database': 'any_approval',\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "# end_year â†’ approval_data í…Œì´ë¸” ë§¤í•‘\n",
    "APPROVAL_TABLE_MAPPING = {\n",
    "    2010: 'approval_data_2010',\n",
    "    2015: 'approval_data_2015',\n",
    "    2020: 'approval_data_2020',\n",
    "    2025: 'approval_data_2025'\n",
    "}\n",
    "\n",
    "# status â†’ actionLogType ë§¤í•‘\n",
    "STATUS_MAPPING = {\n",
    "    'ê¸°ì•ˆ': 'DRAFT',\n",
    "    'ìŠ¹ì¸': 'APPROVAL',\n",
    "    'í•©ì˜': 'AGREEMENT',\n",
    "    'í•©ì˜(ëŒ€ê²°)': 'AGREEMENT',\n",
    "    'ë°˜ë ¤': 'RETURN'\n",
    "}\n",
    "\n",
    "print('ì„¤ì • ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹œê°„ ë³€í™˜ ìœ í‹¸ë¦¬í‹°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unix_ms_to_datetime(unix_ms):\n",
    "    \"\"\"Unix milliseconds â†’ datetime ë³€í™˜\"\"\"\n",
    "    if not unix_ms:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.fromtimestamp(unix_ms / 1000)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def times_match(dt1, dt2, tolerance_seconds=60):\n",
    "    \"\"\"ë‘ ì‹œê°„ì´ í—ˆìš© ì˜¤ì°¨ ë‚´ì—ì„œ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    if dt1 is None or dt2 is None:\n",
    "        return False\n",
    "    diff = abs((dt1 - dt2).total_seconds())\n",
    "    return diff <= tolerance_seconds\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_unix = 1611108241000\n",
    "test_dt = unix_ms_to_datetime(test_unix)\n",
    "print(f'Unix ms {test_unix} â†’ {test_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. documents í…Œì´ë¸” ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents():\n",
    "    \"\"\"documents í…Œì´ë¸”ì—ì„œ source_id, end_year, activities ì¡°íšŒ\"\"\"\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    \n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT source_id, end_year, title, activities\n",
    "        FROM documents\n",
    "        ORDER BY end_year, source_id\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        print(f'âœ… documents í…Œì´ë¸”: {len(df)}ê±´ ì¡°íšŒ')\n",
    "        print(df.groupby('end_year').size())\n",
    "        return df\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "documents_df = get_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. approval_data í…Œì´ë¸”ë“¤ ì¡°íšŒ (approval_date í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approval_data():\n",
    "    \"\"\"ëª¨ë“  approval_data í…Œì´ë¸” ì¡°íšŒ (approval_date í¬í•¨)\"\"\"\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    all_data = []\n",
    "    \n",
    "    try:\n",
    "        for end_year, table_name in APPROVAL_TABLE_MAPPING.items():\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                document_id,\n",
    "                sequence,\n",
    "                status,\n",
    "                approver,\n",
    "                approval_date,\n",
    "                {end_year} as end_year\n",
    "            FROM {table_name}\n",
    "            ORDER BY document_id, sequence\n",
    "            \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "            print(f'âœ… {table_name}: {len(df)}ê±´')\n",
    "            all_data.append(df)\n",
    "        \n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f'\\nğŸ“Š ì „ì²´ approval_data: {len(combined_df)}ê±´')\n",
    "        return combined_df\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "approval_df = get_approval_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬ í˜„í™© í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°™ì€ ë¬¸ì„œì—ì„œ ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ì¼€ì´ìŠ¤ í™•ì¸\n",
    "def check_duplicate_approvers(approval_df):\n",
    "    # approverì—ì„œ ì´ë¦„ë§Œ ì¶”ì¶œ\n",
    "    def extract_name(approver):\n",
    "        parts = str(approver).split() if approver else []\n",
    "        if len(parts) > 1:\n",
    "            return ' '.join(parts[:-1])\n",
    "        return parts[0] if parts else ''\n",
    "    \n",
    "    approval_df['approver_name'] = approval_df['approver'].apply(extract_name)\n",
    "    \n",
    "    # (document_id, end_year, approver_name) ë³„ ê±´ìˆ˜\n",
    "    grouped = approval_df.groupby(['document_id', 'end_year', 'approver_name']).size().reset_index(name='count')\n",
    "    duplicates = grouped[grouped['count'] > 1]\n",
    "    \n",
    "    print(f'ğŸ“Š ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬ í˜„í™©:')\n",
    "    print(f'   - í•´ë‹¹ ì¼€ì´ìŠ¤ ìˆ˜: {len(duplicates)}ê±´')\n",
    "    print(f'   - ìµœëŒ€ ê²°ì¬ íšŸìˆ˜: {duplicates[\"count\"].max() if len(duplicates) > 0 else 0}íšŒ')\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(f'\\nê²°ì¬ íšŸìˆ˜ ë¶„í¬:')\n",
    "        print(duplicates['count'].value_counts().sort_index())\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "duplicate_cases = check_duplicate_approvers(approval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë¶ˆì¼ì¹˜ ê²€ì¦ ì‹¤í–‰ (ì‹œê°„ ë¹„êµ ì¶”ê°€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_action_types_with_time(documents_df, approval_df, tolerance_seconds=60):\n",
    "    \"\"\"\n",
    "    ì‹œê°„ê¹Œì§€ ë¹„êµí•˜ì—¬ ë¶ˆì¼ì¹˜ ê²€ì¦\n",
    "    - ê°™ì€ ì‚¬ëŒ 1ë²ˆ ê²°ì¬: ì´ë¦„ë§Œìœ¼ë¡œ ë§¤ì¹­\n",
    "    - ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬: ì´ë¦„ + ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­\n",
    "    \"\"\"\n",
    "    mismatches = []\n",
    "    \n",
    "    # approval_dataë¥¼ dictë¡œ ë³€í™˜\n",
    "    # key: (document_id, end_year, approver_name)\n",
    "    # value: [(status, approval_date), ...] ë¦¬ìŠ¤íŠ¸\n",
    "    approval_dict = {}\n",
    "    \n",
    "    for _, row in approval_df.iterrows():\n",
    "        approver_parts = str(row['approver']).split() if row['approver'] else []\n",
    "        if len(approver_parts) > 1:\n",
    "            approver_name = ' '.join(approver_parts[:-1])\n",
    "        else:\n",
    "            approver_name = approver_parts[0] if approver_parts else ''\n",
    "        \n",
    "        key = (str(row['document_id']), row['end_year'], approver_name)\n",
    "        \n",
    "        # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ (status, approval_date íŠœí”Œ)\n",
    "        if key not in approval_dict:\n",
    "            approval_dict[key] = []\n",
    "        approval_dict[key].append({\n",
    "            'status': row['status'],\n",
    "            'approval_date': row['approval_date'],\n",
    "            'sequence': row['sequence']\n",
    "        })\n",
    "    \n",
    "    print(f'approval_dict ìƒì„± ì™„ë£Œ: {len(approval_dict)}ê±´')\n",
    "    \n",
    "    total = len(documents_df)\n",
    "    matched_count = 0\n",
    "    not_found_count = 0\n",
    "    time_matched_count = 0  # ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­ëœ ì¼€ì´ìŠ¤\n",
    "    \n",
    "    for idx, row in documents_df.iterrows():\n",
    "        source_id = str(row['source_id'])\n",
    "        end_year = row['end_year']\n",
    "        title = row['title']\n",
    "        \n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f'ì§„í–‰: {idx + 1}/{total}')\n",
    "        \n",
    "        try:\n",
    "            activities = json.loads(row['activities'], strict=False) if row['activities'] else []\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        for act in activities:\n",
    "            name = act.get('name', '')\n",
    "            db_type = act.get('actionLogType', '')\n",
    "            action_date_ms = act.get('actionDate')\n",
    "            action_date = unix_ms_to_datetime(action_date_ms)\n",
    "            \n",
    "            if not name:\n",
    "                continue\n",
    "            \n",
    "            key = (source_id, end_year, name)\n",
    "            \n",
    "            if key not in approval_dict:\n",
    "                not_found_count += 1\n",
    "                continue\n",
    "            \n",
    "            matched_count += 1\n",
    "            approval_list = approval_dict[key]\n",
    "            \n",
    "            # ê°™ì€ ì‚¬ëŒì´ 1ë²ˆë§Œ ê²°ì¬í•œ ê²½ìš°: ê¸°ì¡´ ë¡œì§\n",
    "            if len(approval_list) == 1:\n",
    "                expected_type = STATUS_MAPPING.get(approval_list[0]['status'], '')\n",
    "                if db_type != expected_type:\n",
    "                    mismatches.append({\n",
    "                        'source_id': source_id,\n",
    "                        'end_year': end_year,\n",
    "                        'title': title,\n",
    "                        'name': name,\n",
    "                        'approval_status': approval_list[0]['status'],\n",
    "                        'expected_type': expected_type,\n",
    "                        'db_type': db_type,\n",
    "                        'action_date': action_date,\n",
    "                        'approval_date': approval_list[0]['approval_date'],\n",
    "                        'match_type': 'single'\n",
    "                    })\n",
    "            \n",
    "            # ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ê²½ìš°: ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­\n",
    "            else:\n",
    "                time_matched = False\n",
    "                matched_approval = None\n",
    "                \n",
    "                for appr in approval_list:\n",
    "                    appr_date = appr['approval_date']\n",
    "                    if times_match(action_date, appr_date, tolerance_seconds):\n",
    "                        time_matched = True\n",
    "                        matched_approval = appr\n",
    "                        time_matched_count += 1\n",
    "                        break\n",
    "                \n",
    "                if time_matched and matched_approval:\n",
    "                    expected_type = STATUS_MAPPING.get(matched_approval['status'], '')\n",
    "                    if db_type != expected_type:\n",
    "                        mismatches.append({\n",
    "                            'source_id': source_id,\n",
    "                            'end_year': end_year,\n",
    "                            'title': title,\n",
    "                            'name': name,\n",
    "                            'approval_status': matched_approval['status'],\n",
    "                            'expected_type': expected_type,\n",
    "                            'db_type': db_type,\n",
    "                            'action_date': action_date,\n",
    "                            'approval_date': matched_approval['approval_date'],\n",
    "                            'match_type': 'time_matched'\n",
    "                        })\n",
    "                else:\n",
    "                    # ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ - ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ ì°¾ê¸°\n",
    "                    closest = None\n",
    "                    min_diff = float('inf')\n",
    "                    \n",
    "                    for appr in approval_list:\n",
    "                        appr_date = appr['approval_date']\n",
    "                        if action_date and appr_date:\n",
    "                            diff = abs((action_date - appr_date).total_seconds())\n",
    "                            if diff < min_diff:\n",
    "                                min_diff = diff\n",
    "                                closest = appr\n",
    "                    \n",
    "                    # ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ê¸°ë¡ (ë³„ë„ ì¹´í…Œê³ ë¦¬)\n",
    "                    mismatches.append({\n",
    "                        'source_id': source_id,\n",
    "                        'end_year': end_year,\n",
    "                        'title': title,\n",
    "                        'name': name,\n",
    "                        'approval_status': f\"[ì—¬ëŸ¬ ê±´: {[a['status'] for a in approval_list]}]\",\n",
    "                        'expected_type': f\"[ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨, ì˜¤ì°¨: {min_diff:.0f}ì´ˆ]\",\n",
    "                        'db_type': db_type,\n",
    "                        'action_date': action_date,\n",
    "                        'approval_date': f\"[{[str(a['approval_date']) for a in approval_list]}]\",\n",
    "                        'match_type': 'time_mismatch'\n",
    "                    })\n",
    "    \n",
    "    print(f'\\nâœ… ê²€ì¦ ì™„ë£Œ')\n",
    "    print(f'   ë§¤ì¹­ ì„±ê³µ: {matched_count}ê±´')\n",
    "    print(f'   ë§¤ì¹­ ì‹¤íŒ¨ (approval_dataì— ì—†ìŒ): {not_found_count}ê±´')\n",
    "    print(f'   ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­ëœ ì¼€ì´ìŠ¤: {time_matched_count}ê±´')\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "# ê²€ì¦ ì‹¤í–‰\n",
    "print('ê²€ì¦ ì‹œì‘...')\n",
    "mismatches = verify_action_types_with_time(documents_df, approval_df, tolerance_seconds=60)\n",
    "print(f'\\nğŸ”´ ë¶ˆì¼ì¹˜ ë°œê²¬: {len(mismatches)}ê±´')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    print('ğŸ“Š ë§¤ì¹­ íƒ€ì…ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:')\n",
    "    print(result_df.groupby('match_type').size())\n",
    "    \n",
    "    print('\\nğŸ“Š ì—°ë„ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:')\n",
    "    print(result_df.groupby('end_year').size())\n",
    "    \n",
    "    print('\\nğŸ“Š ê²°ì¬ìë³„ ë¶ˆì¼ì¹˜ í˜„í™© (ìƒìœ„ 20ëª…):')\n",
    "    print(result_df.groupby('name').size().sort_values(ascending=False).head(20))\n",
    "    \n",
    "    # ìƒì„¸ ë‚´ìš© ì¶œë ¥\n",
    "    print('\\n' + '='*80)\n",
    "    print('ìƒì„¸ ë¶ˆì¼ì¹˜ ëª©ë¡ (ì²˜ìŒ 20ê±´):')\n",
    "    print('='*80)\n",
    "    \n",
    "    for i, row in result_df.head(20).iterrows():\n",
    "        print(f\"\\n[{i+1}] source_id: {row['source_id']} (end_year: {row['end_year']})\")\n",
    "        print(f\"    ì œëª©: {row['title'][:50]}...\" if len(str(row['title'])) > 50 else f\"    ì œëª©: {row['title']}\")\n",
    "        print(f\"    ê²°ì¬ì: {row['name']}\")\n",
    "        print(f\"    ë§¤ì¹­ íƒ€ì…: {row['match_type']}\")\n",
    "        print(f\"    approval_data: {row['approval_status']} â†’ ì˜ˆìƒ: {row['expected_type']}\")\n",
    "        print(f\"    documents: {row['db_type']} âŒ\")\n",
    "        print(f\"    ì‹œê°„ - activities: {row['action_date']}\")\n",
    "        print(f\"    ì‹œê°„ - approval_data: {row['approval_date']}\")\n",
    "else:\n",
    "    print('ğŸ‰ ë¶ˆì¼ì¹˜ ì—†ìŒ! ëª¨ë“  actionLogTypeì´ ì •í™•í•©ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    time_mismatch_df = result_df[result_df['match_type'] == 'time_mismatch']\n",
    "    \n",
    "    if len(time_mismatch_df) > 0:\n",
    "        print(f'ğŸ“Š ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤: {len(time_mismatch_df)}ê±´')\n",
    "        print('\\nì´ ì¼€ì´ìŠ¤ë“¤ì€ ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í–ˆëŠ”ë° ì‹œê°„ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì…ë‹ˆë‹¤.')\n",
    "        print('tolerance_seconds ê°’ì„ ëŠ˜ë¦¬ë©´ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n')\n",
    "        \n",
    "        for i, row in time_mismatch_df.head(10).iterrows():\n",
    "            print(f\"source_id: {row['source_id']}, ê²°ì¬ì: {row['name']}\")\n",
    "            print(f\"  activities ì‹œê°„: {row['action_date']}\")\n",
    "            print(f\"  approval_data ì‹œê°„ë“¤: {row['approval_date']}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ê²°ê³¼ CSV ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    output_file = 'actionType_ë¶ˆì¼ì¹˜ëª©ë¡_ì‹œê°„ë¹„êµ.csv'\n",
    "    result_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f'âœ… ì €ì¥ ì™„ë£Œ: {output_file}')\n",
    "    print(f'   ì´ {len(result_df)}ê±´ì˜ ë¶ˆì¼ì¹˜ ë°œê²¬')\n",
    "else:\n",
    "    print('ë¶ˆì¼ì¹˜ê°€ ì—†ì–´ì„œ CSVë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. (ì„ íƒ) ë¶ˆì¼ì¹˜ DB ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ë°±ì—…í•˜ì„¸ìš”!\n",
    "UPDATE_DB = False  # Trueë¡œ ë°”ê¾¸ë©´ ì‹¤í–‰ë¨\n",
    "\n",
    "if UPDATE_DB and mismatches:\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    # time_mismatchëŠ” ì œì™¸ (ë¶ˆí™•ì‹¤)\n",
    "    update_df = result_df[result_df['match_type'] != 'time_mismatch']\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    doc_updates = defaultdict(list)\n",
    "    \n",
    "    for _, m in update_df.iterrows():\n",
    "        key = (m['source_id'], m['end_year'])\n",
    "        expected_type = m['expected_type']\n",
    "        if expected_type and not expected_type.startswith('['):\n",
    "            doc_updates[key].append({\n",
    "                'name': m['name'],\n",
    "                'expected_type': expected_type,\n",
    "                'action_date': m['action_date']\n",
    "            })\n",
    "    \n",
    "    updated = 0\n",
    "    \n",
    "    for (source_id, end_year), updates in doc_updates.items():\n",
    "        cursor.execute(\n",
    "            \"SELECT activities FROM documents WHERE source_id = %s AND end_year = %s\",\n",
    "            (source_id, end_year)\n",
    "        )\n",
    "        row = cursor.fetchone()\n",
    "        if not row:\n",
    "            continue\n",
    "        \n",
    "        activities = json.loads(row[0]) if row[0] else []\n",
    "        \n",
    "        modified = False\n",
    "        for upd in updates:\n",
    "            for act in activities:\n",
    "                # ì´ë¦„ê³¼ ì‹œê°„ ë‘˜ ë‹¤ ë§¤ì¹­\n",
    "                if act.get('name') == upd['name']:\n",
    "                    act_date = unix_ms_to_datetime(act.get('actionDate'))\n",
    "                    if times_match(act_date, upd['action_date'], tolerance_seconds=60) or len(updates) == 1:\n",
    "                        act['actionLogType'] = upd['expected_type']\n",
    "                        act['type'] = upd['expected_type']\n",
    "                        modified = True\n",
    "                        break\n",
    "        \n",
    "        if modified:\n",
    "            cursor.execute(\n",
    "                \"UPDATE documents SET activities = %s WHERE source_id = %s AND end_year = %s\",\n",
    "                (json.dumps(activities, ensure_ascii=False), source_id, end_year)\n",
    "            )\n",
    "            updated += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f'âœ… {updated}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ')\n",
    "    print(f'   (time_mismatch ì¼€ì´ìŠ¤ëŠ” ì œì™¸ë¨)')\n",
    "else:\n",
    "    print('UPDATE_DB = Trueë¡œ ì„¤ì •í•˜ë©´ ë¶ˆì¼ì¹˜ê°€ DBì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
