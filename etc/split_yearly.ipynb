{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMDS 파일 연도별 분리 및 정렬\n",
    "\n",
    "## 목적\n",
    "- `createdAt` 타임스탬프 기준으로 연도별 파일 분리\n",
    "- 각 연도 파일 내에서 `sourceId` 오름차순 정렬\n",
    "- **줄 내용은 한 글자도 수정하지 않음**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 파일: C:\\Users\\LEEJUHWAN\\Desktop\\애니파이브\\전자결재\\새로 다 다시 이관\\documents_referrers_fixed.cmds\n",
      "출력 폴더: C:\\Users\\LEEJUHWAN\\Desktop\\애니파이브\\전자결재\\새로 다 다시 이관\\yearly\n"
     ]
    }
   ],
   "source": [
    "# ========== 경로 설정 (필요시 수정) ==========\n",
    "BASE_DIR = r'C:\\Users\\LEEJUHWAN\\Desktop\\애니파이브\\전자결재\\새로 다 다시 이관'\n",
    "\n",
    "CMDS_INPUT_PATH = os.path.join(BASE_DIR, 'documents_referrers_fixed.cmds')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'yearly')  # 연도별 파일 저장 폴더\n",
    "\n",
    "# 출력 폴더 생성\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"입력 파일: {CMDS_INPUT_PATH}\")\n",
    "print(f\"출력 폴더: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 줄 수: 23320개\n"
     ]
    }
   ],
   "source": [
    "with open(CMDS_INPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"총 줄 수: {len(lines)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdAt: 1609740886000\n",
      "sourceId: doc_15167823_06\n",
      "연도: 2021\n"
     ]
    }
   ],
   "source": [
    "def extract_created_at(line):\n",
    "    \"\"\"줄에서 createdAt 값 추출 (밀리초 타임스탬프)\"\"\"\n",
    "    match = re.search(r'\"createdAt\":(\\d+)', line)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_source_id(line):\n",
    "    \"\"\"줄에서 sourceId 값 추출\"\"\"\n",
    "    match = re.search(r'\"sourceId\":\"([^\"]+)\"', line)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "\n",
    "def timestamp_to_year(timestamp_ms):\n",
    "    \"\"\"밀리초 타임스탬프 → 연도 (한국시간)\"\"\"\n",
    "    dt = datetime.fromtimestamp(timestamp_ms / 1000, tz=KST)\n",
    "    return dt.year\n",
    "\n",
    "# 테스트\n",
    "test_line = lines[0]\n",
    "print(f\"createdAt: {extract_created_at(test_line)}\")\n",
    "print(f\"sourceId: {extract_source_id(test_line)}\")\n",
    "print(f\"연도: {timestamp_to_year(extract_created_at(test_line))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 연도별 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연도별 문서 수:\n",
      "  2010년: 841개\n",
      "  2011년: 855개\n",
      "  2012년: 1280개\n",
      "  2013년: 1582개\n",
      "  2014년: 1504개\n",
      "  2015년: 1367개\n",
      "  2016년: 1528개\n",
      "  2017년: 1963개\n",
      "  2018년: 1661개\n",
      "  2019년: 1478개\n",
      "  2020년: 1075개\n",
      "  2021년: 1331개\n",
      "  2022년: 1818개\n",
      "  2023년: 1442개\n",
      "  2024년: 1811개\n",
      "  2025년: 1784개\n"
     ]
    }
   ],
   "source": [
    "# 연도별로 (sourceId, 원본줄) 저장\n",
    "yearly_data = defaultdict(list)\n",
    "parse_errors = []\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.rstrip('\\n')\n",
    "    \n",
    "    if not line.strip():\n",
    "        continue\n",
    "    \n",
    "    created_at = extract_created_at(line)\n",
    "    source_id = extract_source_id(line)\n",
    "    \n",
    "    if created_at is None:\n",
    "        parse_errors.append((i+1, 'createdAt 없음', line[:100]))\n",
    "        continue\n",
    "    \n",
    "    if source_id is None:\n",
    "        parse_errors.append((i+1, 'sourceId 없음', line[:100]))\n",
    "        continue\n",
    "    \n",
    "    year = timestamp_to_year(created_at)\n",
    "    yearly_data[year].append((source_id, line))\n",
    "\n",
    "print(f\"연도별 문서 수:\")\n",
    "for year in sorted(yearly_data.keys()):\n",
    "    print(f\"  {year}년: {len(yearly_data[year])}개\")\n",
    "\n",
    "if parse_errors:\n",
    "    print(f\"\\n파싱 에러: {len(parse_errors)}개\")\n",
    "    for line_no, err, preview in parse_errors[:5]:\n",
    "        print(f\"  Line {line_no}: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. sourceId 기준 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정렬 완료!\n",
      "\n",
      "2010년 첫 5개 sourceId:\n",
      "  doc_2002067_06\n",
      "  doc_2002068_06\n",
      "  doc_2002069_06\n",
      "  doc_2002070_06\n",
      "  doc_2002071_06\n"
     ]
    }
   ],
   "source": [
    "def sort_key(source_id):\n",
    "    \"\"\"\n",
    "    sourceId 정렬 키\n",
    "    예: doc_12345_06 → 숫자 부분으로 정렬\n",
    "    \"\"\"\n",
    "    # 숫자 부분 추출 시도\n",
    "    match = re.search(r'doc_(\\d+)', source_id)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    # 숫자 없으면 문자열 그대로\n",
    "    return source_id\n",
    "\n",
    "# 각 연도별로 정렬\n",
    "for year in yearly_data:\n",
    "    yearly_data[year].sort(key=lambda x: sort_key(x[0]))\n",
    "\n",
    "print(\"정렬 완료!\")\n",
    "\n",
    "# 정렬 확인 (첫 연도 샘플)\n",
    "first_year = min(yearly_data.keys())\n",
    "print(f\"\\n{first_year}년 첫 5개 sourceId:\")\n",
    "for source_id, _ in yearly_data[first_year][:5]:\n",
    "    print(f\"  {source_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문서 수: 23320개\n",
      "분류된 문서 수: 23320개\n",
      "파싱 에러: 0개\n",
      "합계: 23320개\n",
      "\n",
      "✅ 문서 수 일치!\n"
     ]
    }
   ],
   "source": [
    "# 총 문서 수 확인\n",
    "total_in_yearly = sum(len(v) for v in yearly_data.values())\n",
    "total_original = len([l for l in lines if l.strip()])\n",
    "\n",
    "print(f\"원본 문서 수: {total_original}개\")\n",
    "print(f\"분류된 문서 수: {total_in_yearly}개\")\n",
    "print(f\"파싱 에러: {len(parse_errors)}개\")\n",
    "print(f\"합계: {total_in_yearly + len(parse_errors)}개\")\n",
    "\n",
    "if total_original == total_in_yearly + len(parse_errors):\n",
    "    print(\"\\n✅ 문서 수 일치!\")\n",
    "else:\n",
    "    print(\"\\n❌ 문서 수 불일치!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 줄 무결성 확인 (샘플):\n",
      "  Line 0: ✅ 일치\n",
      "  Line 100: ✅ 일치\n",
      "  Line 500: ✅ 일치\n",
      "  Line 1000: ✅ 일치\n",
      "  Line 5000: ✅ 일치\n",
      "\n",
      "✅ 원본 줄 무결성 확인 완료!\n"
     ]
    }
   ],
   "source": [
    "# 원본 줄이 그대로인지 확인 (샘플)\n",
    "print(\"원본 줄 무결성 확인 (샘플):\")\n",
    "\n",
    "# 원본에서 몇 개 랜덤 선택해서 yearly_data에 동일하게 있는지 확인\n",
    "sample_indices = [0, 100, 500, 1000, 5000]\n",
    "all_lines_in_yearly = []\n",
    "for year in yearly_data:\n",
    "    for source_id, line in yearly_data[year]:\n",
    "        all_lines_in_yearly.append(line)\n",
    "\n",
    "mismatch = 0\n",
    "for idx in sample_indices:\n",
    "    if idx < len(lines):\n",
    "        orig = lines[idx].rstrip('\\n')\n",
    "        if orig.strip() and orig in all_lines_in_yearly:\n",
    "            print(f\"  Line {idx}: ✅ 일치\")\n",
    "        elif orig.strip():\n",
    "            print(f\"  Line {idx}: ❌ 불일치\")\n",
    "            mismatch += 1\n",
    "\n",
    "if mismatch == 0:\n",
    "    print(\"\\n✅ 원본 줄 무결성 확인 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 연도별 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ documents_2010.cmds: 841개 문서, 39.75 MB\n",
      "✅ documents_2011.cmds: 855개 문서, 51.12 MB\n",
      "✅ documents_2012.cmds: 1280개 문서, 70.65 MB\n",
      "✅ documents_2013.cmds: 1582개 문서, 77.97 MB\n",
      "✅ documents_2014.cmds: 1504개 문서, 70.57 MB\n",
      "✅ documents_2015.cmds: 1367개 문서, 49.90 MB\n",
      "✅ documents_2016.cmds: 1528개 문서, 48.76 MB\n",
      "✅ documents_2017.cmds: 1963개 문서, 64.14 MB\n",
      "✅ documents_2018.cmds: 1661개 문서, 56.05 MB\n",
      "✅ documents_2019.cmds: 1478개 문서, 53.26 MB\n",
      "✅ documents_2020.cmds: 1075개 문서, 27.03 MB\n",
      "✅ documents_2021.cmds: 1331개 문서, 43.26 MB\n",
      "✅ documents_2022.cmds: 1818개 문서, 69.17 MB\n",
      "✅ documents_2023.cmds: 1442개 문서, 49.07 MB\n",
      "✅ documents_2024.cmds: 1811개 문서, 60.20 MB\n",
      "✅ documents_2025.cmds: 1784개 문서, 62.33 MB\n",
      "\n",
      "총 16개 파일 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "saved_files = []\n",
    "\n",
    "for year in sorted(yearly_data.keys()):\n",
    "    filename = f\"documents_{year}.cmds\"\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for source_id, line in yearly_data[year]:\n",
    "            f.write(line + '\\n')\n",
    "    \n",
    "    file_size = os.path.getsize(filepath) / 1024 / 1024\n",
    "    saved_files.append((year, len(yearly_data[year]), file_size))\n",
    "    print(f\"✅ {filename}: {len(yearly_data[year])}개 문서, {file_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\n총 {len(saved_files)}개 파일 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파싱 에러 없음\n"
     ]
    }
   ],
   "source": [
    "# 파싱 에러 문서 별도 저장 (있는 경우)\n",
    "if parse_errors:\n",
    "    error_filepath = os.path.join(OUTPUT_DIR, 'documents_parse_error.cmds')\n",
    "    with open(error_filepath, 'w', encoding='utf-8') as f:\n",
    "        for line_no, err, preview in parse_errors:\n",
    "            # 원본 줄 저장\n",
    "            orig_line = lines[line_no - 1].rstrip('\\n')\n",
    "            f.write(orig_line + '\\n')\n",
    "    print(f\"⚠️ 파싱 에러 문서 저장: {error_filepath}\")\n",
    "else:\n",
    "    print(\"파싱 에러 없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완료!\n",
    "\n",
    "### 결과\n",
    "- `yearly/documents_YYYY.cmds` - 연도별 파일 (sourceId 오름차순 정렬)\n",
    "- `yearly/documents_parse_error.cmds` - 파싱 에러 문서 (있는 경우)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
