{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actionLogType / type ë¶ˆì¼ì¹˜ ê²€ì¦ (ì‹œê°„ ë¹„êµ ì¶”ê°€)\n",
    "documents.activitiesì™€ approval_data_XXXX í…Œì´ë¸” ë¹„êµ\n",
    "\n",
    "**ë³€ê²½ì‚¬í•­**: ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ê²½ìš°, ì‹œê°„ê¹Œì§€ ë¹„êµí•˜ì—¬ ì •í™•íˆ 1:1 ë§¤ì¹­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# returnì€ approvalë¡œ í•˜ê¸°ë¡œ í–ˆê³  (48ê±´)\n",
    "# ë‚¨ì€ 2ê±´ì€ 1ë¶„ ë‚´ì— ê°™ì€ì‚¬ëŒì´ ë‘ë²ˆ ê²°ì¬ ì˜¬ë¦°ê²ƒ. tolerance_seconds=60ìœ¼ë¡œ ì„¤ì •ë˜ì–´ìˆì–´ì„œ ì—¬ê¸°ì„œ ê±¸ë¦¼.\n",
    "# => 50ê±´ ëª¨ë‘ ë¬¸ì œ ì—†ìŒ.\n",
    "\n",
    "import json\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# DB ì„¤ì •\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'database': 'any_approval',\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "# end_year â†’ approval_data í…Œì´ë¸” ë§¤í•‘\n",
    "APPROVAL_TABLE_MAPPING = {\n",
    "    2010: 'approval_data_2010',\n",
    "    2015: 'approval_data_2015',\n",
    "    2020: 'approval_data_2020',\n",
    "    2025: 'approval_data_2025'\n",
    "}\n",
    "\n",
    "# status â†’ actionLogType ë§¤í•‘\n",
    "STATUS_MAPPING = {\n",
    "    'ê¸°ì•ˆ': 'DRAFT',\n",
    "    'ìŠ¹ì¸': 'APPROVAL',\n",
    "    'í•©ì˜': 'AGREEMENT',\n",
    "    'í•©ì˜(ëŒ€ê²°)': 'AGREEMENT',\n",
    "    'ë°˜ë ¤': 'RETURN'\n",
    "}\n",
    "\n",
    "print('ì„¤ì • ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹œê°„ ë³€í™˜ ìœ í‹¸ë¦¬í‹°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unix ms 1611108241000 â†’ 2021-01-20 11:04:01\n"
     ]
    }
   ],
   "source": [
    "def unix_ms_to_datetime(unix_ms):\n",
    "    \"\"\"Unix milliseconds â†’ datetime ë³€í™˜\"\"\"\n",
    "    if not unix_ms:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.fromtimestamp(unix_ms / 1000)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_datetime(dt):\n",
    "    \"\"\"ë‹¤ì–‘í•œ í˜•ì‹ì˜ datetimeì„ ì²˜ë¦¬\"\"\"\n",
    "    if dt is None:\n",
    "        return None\n",
    "    if isinstance(dt, datetime):\n",
    "        return dt\n",
    "    if isinstance(dt, str):\n",
    "        try:\n",
    "            return datetime.strptime(dt, '%Y-%m-%d %H:%M:%S')\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def times_match(dt1, dt2, tolerance_seconds=60):\n",
    "    \"\"\"ë‘ ì‹œê°„ì´ í—ˆìš© ì˜¤ì°¨ ë‚´ì—ì„œ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    dt1 = parse_datetime(dt1)\n",
    "    dt2 = parse_datetime(dt2)\n",
    "    if dt1 is None or dt2 is None:\n",
    "        return False\n",
    "    diff = abs((dt1 - dt2).total_seconds())\n",
    "    return diff <= tolerance_seconds\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_unix = 1611108241000\n",
    "test_dt = unix_ms_to_datetime(test_unix)\n",
    "print(f'Unix ms {test_unix} â†’ {test_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. documents í…Œì´ë¸” ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEEJUHWAN\\AppData\\Local\\Temp\\ipykernel_31952\\556317999.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… documents í…Œì´ë¸”: 23320ê±´ ì¡°íšŒ\n",
      "end_year\n",
      "2010     841\n",
      "2015    6588\n",
      "2020    7705\n",
      "2025    8186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_documents():\n",
    "    \"\"\"documents í…Œì´ë¸”ì—ì„œ source_id, end_year, activities ì¡°íšŒ\"\"\"\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    \n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT source_id, end_year, title, activities\n",
    "        FROM documents\n",
    "        ORDER BY end_year, source_id\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        print(f'âœ… documents í…Œì´ë¸”: {len(df)}ê±´ ì¡°íšŒ')\n",
    "        print(df.groupby('end_year').size())\n",
    "        return df\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "documents_df = get_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. approval_data í…Œì´ë¸”ë“¤ ì¡°íšŒ (approval_date í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEEJUHWAN\\AppData\\Local\\Temp\\ipykernel_31952\\586048261.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… approval_data_2010: 2899ê±´\n",
      "âœ… approval_data_2015: 23718ê±´\n",
      "âœ… approval_data_2020: 27563ê±´\n",
      "âœ… approval_data_2025: 25939ê±´\n",
      "\n",
      "ğŸ“Š ì „ì²´ approval_data: 80119ê±´\n"
     ]
    }
   ],
   "source": [
    "def get_approval_data():\n",
    "    \"\"\"ëª¨ë“  approval_data í…Œì´ë¸” ì¡°íšŒ (approval_date í¬í•¨)\"\"\"\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    all_data = []\n",
    "    \n",
    "    try:\n",
    "        for end_year, table_name in APPROVAL_TABLE_MAPPING.items():\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                document_id,\n",
    "                sequence,\n",
    "                status,\n",
    "                approver,\n",
    "                approval_date,\n",
    "                {end_year} as end_year\n",
    "            FROM {table_name}\n",
    "            ORDER BY document_id, sequence\n",
    "            \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "            print(f'âœ… {table_name}: {len(df)}ê±´')\n",
    "            all_data.append(df)\n",
    "        \n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f'\\nğŸ“Š ì „ì²´ approval_data: {len(combined_df)}ê±´')\n",
    "        return combined_df\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "approval_df = get_approval_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬ í˜„í™© í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬ í˜„í™©:\n",
      "   - í•´ë‹¹ ì¼€ì´ìŠ¤ ìˆ˜: 23ê±´\n",
      "   - ìµœëŒ€ ê²°ì¬ íšŸìˆ˜: 3íšŒ\n",
      "\n",
      "ê²°ì¬ íšŸìˆ˜ ë¶„í¬:\n",
      "count\n",
      "2    22\n",
      "3     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ê°™ì€ ë¬¸ì„œì—ì„œ ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ì¼€ì´ìŠ¤ í™•ì¸\n",
    "def check_duplicate_approvers(approval_df):\n",
    "    # approverì—ì„œ ì´ë¦„ë§Œ ì¶”ì¶œ\n",
    "    def extract_name(approver):\n",
    "        parts = str(approver).split() if approver else []\n",
    "        if len(parts) > 1:\n",
    "            return ' '.join(parts[:-1])\n",
    "        return parts[0] if parts else ''\n",
    "    \n",
    "    approval_df['approver_name'] = approval_df['approver'].apply(extract_name)\n",
    "    \n",
    "    # (document_id, end_year, approver_name) ë³„ ê±´ìˆ˜\n",
    "    grouped = approval_df.groupby(['document_id', 'end_year', 'approver_name']).size().reset_index(name='count')\n",
    "    duplicates = grouped[grouped['count'] > 1]\n",
    "    \n",
    "    print(f'ğŸ“Š ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬ í˜„í™©:')\n",
    "    print(f'   - í•´ë‹¹ ì¼€ì´ìŠ¤ ìˆ˜: {len(duplicates)}ê±´')\n",
    "    print(f'   - ìµœëŒ€ ê²°ì¬ íšŸìˆ˜: {duplicates[\"count\"].max() if len(duplicates) > 0 else 0}íšŒ')\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(f'\\nê²°ì¬ íšŸìˆ˜ ë¶„í¬:')\n",
    "        print(duplicates['count'].value_counts().sort_index())\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "duplicate_cases = check_duplicate_approvers(approval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë¶ˆì¼ì¹˜ ê²€ì¦ ì‹¤í–‰ (ì‹œê°„ ë¹„êµ ì¶”ê°€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì¦ ì‹œì‘...\n",
      "approval_dict ìƒì„± ì™„ë£Œ: 80095ê±´\n",
      "ì§„í–‰: 1000/23320\n",
      "ì§„í–‰: 2000/23320\n",
      "ì§„í–‰: 3000/23320\n",
      "ì§„í–‰: 4000/23320\n",
      "ì§„í–‰: 5000/23320\n",
      "ì§„í–‰: 6000/23320\n",
      "ì§„í–‰: 7000/23320\n",
      "ì§„í–‰: 8000/23320\n",
      "ì§„í–‰: 9000/23320\n",
      "ì§„í–‰: 10000/23320\n",
      "ì§„í–‰: 11000/23320\n",
      "ì§„í–‰: 12000/23320\n",
      "ì§„í–‰: 13000/23320\n",
      "ì§„í–‰: 14000/23320\n",
      "ì§„í–‰: 15000/23320\n",
      "ì§„í–‰: 16000/23320\n",
      "ì§„í–‰: 17000/23320\n",
      "ì§„í–‰: 18000/23320\n",
      "ì§„í–‰: 19000/23320\n",
      "ì§„í–‰: 20000/23320\n",
      "ì§„í–‰: 21000/23320\n",
      "ì§„í–‰: 22000/23320\n",
      "ì§„í–‰: 23000/23320\n",
      "\n",
      "âœ… ê²€ì¦ ì™„ë£Œ\n",
      "   ë§¤ì¹­ ì„±ê³µ: 80114ê±´\n",
      "   ë§¤ì¹­ ì‹¤íŒ¨ (approval_dataì— ì—†ìŒ): 53ê±´\n",
      "   ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­ëœ ì¼€ì´ìŠ¤: 47ê±´\n",
      "\n",
      "ğŸ”´ ë¶ˆì¼ì¹˜ ë°œê²¬: 50ê±´\n"
     ]
    }
   ],
   "source": [
    "def verify_action_types_with_time(documents_df, approval_df, tolerance_seconds=60):\n",
    "    \"\"\"\n",
    "    ì‹œê°„ê¹Œì§€ ë¹„êµí•˜ì—¬ ë¶ˆì¼ì¹˜ ê²€ì¦\n",
    "    - ê°™ì€ ì‚¬ëŒ 1ë²ˆ ê²°ì¬: ì´ë¦„ë§Œìœ¼ë¡œ ë§¤ì¹­\n",
    "    - ê°™ì€ ì‚¬ëŒ ì—¬ëŸ¬ ë²ˆ ê²°ì¬: ì´ë¦„ + ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­\n",
    "    \"\"\"\n",
    "    mismatches = []\n",
    "    \n",
    "    # approval_dataë¥¼ dictë¡œ ë³€í™˜\n",
    "    # key: (document_id, end_year, approver_name)\n",
    "    # value: [(status, approval_date), ...] ë¦¬ìŠ¤íŠ¸\n",
    "    approval_dict = {}\n",
    "    \n",
    "    for _, row in approval_df.iterrows():\n",
    "        approver_parts = str(row['approver']).split() if row['approver'] else []\n",
    "        if len(approver_parts) > 1:\n",
    "            approver_name = ' '.join(approver_parts[:-1])\n",
    "        else:\n",
    "            approver_name = approver_parts[0] if approver_parts else ''\n",
    "        \n",
    "        key = (str(row['document_id']), row['end_year'], approver_name)\n",
    "        \n",
    "        # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ (status, approval_date íŠœí”Œ)\n",
    "        if key not in approval_dict:\n",
    "            approval_dict[key] = []\n",
    "        approval_dict[key].append({\n",
    "            'status': row['status'],\n",
    "            'approval_date': row['approval_date'],\n",
    "            'sequence': row['sequence']\n",
    "        })\n",
    "    \n",
    "    print(f'approval_dict ìƒì„± ì™„ë£Œ: {len(approval_dict)}ê±´')\n",
    "    \n",
    "    total = len(documents_df)\n",
    "    matched_count = 0\n",
    "    not_found_count = 0\n",
    "    time_matched_count = 0  # ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­ëœ ì¼€ì´ìŠ¤\n",
    "    \n",
    "    for idx, row in documents_df.iterrows():\n",
    "        source_id = str(row['source_id'])\n",
    "        end_year = row['end_year']\n",
    "        title = row['title']\n",
    "        \n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f'ì§„í–‰: {idx + 1}/{total}')\n",
    "        \n",
    "        try:\n",
    "            activities = json.loads(row['activities'], strict=False) if row['activities'] else []\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        for act in activities:\n",
    "            name = act.get('name', '')\n",
    "            db_type = act.get('actionLogType', '')\n",
    "            action_date_ms = act.get('actionDate')\n",
    "            action_date = unix_ms_to_datetime(action_date_ms)\n",
    "            \n",
    "            if not name:\n",
    "                continue\n",
    "            \n",
    "            key = (source_id, end_year, name)\n",
    "            \n",
    "            if key not in approval_dict:\n",
    "                not_found_count += 1\n",
    "                continue\n",
    "            \n",
    "            matched_count += 1\n",
    "            approval_list = approval_dict[key]\n",
    "            \n",
    "            # ê°™ì€ ì‚¬ëŒì´ 1ë²ˆë§Œ ê²°ì¬í•œ ê²½ìš°: ê¸°ì¡´ ë¡œì§\n",
    "            if len(approval_list) == 1:\n",
    "                expected_type = STATUS_MAPPING.get(approval_list[0]['status'], '')\n",
    "                if db_type != expected_type:\n",
    "                    mismatches.append({\n",
    "                        'source_id': source_id,\n",
    "                        'end_year': end_year,\n",
    "                        'title': title,\n",
    "                        'name': name,\n",
    "                        'approval_status': approval_list[0]['status'],\n",
    "                        'expected_type': expected_type,\n",
    "                        'db_type': db_type,\n",
    "                        'action_date': action_date,\n",
    "                        'approval_date': approval_list[0]['approval_date'],\n",
    "                        'match_type': 'single'\n",
    "                    })\n",
    "            \n",
    "            # ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í•œ ê²½ìš°: ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­\n",
    "            else:\n",
    "                time_matched = False\n",
    "                matched_approval = None\n",
    "                \n",
    "                for appr in approval_list:\n",
    "                    appr_date = appr['approval_date']\n",
    "                    if times_match(action_date, appr_date, tolerance_seconds):\n",
    "                        time_matched = True\n",
    "                        matched_approval = appr\n",
    "                        time_matched_count += 1\n",
    "                        break\n",
    "                \n",
    "                if time_matched and matched_approval:\n",
    "                    expected_type = STATUS_MAPPING.get(matched_approval['status'], '')\n",
    "                    if db_type != expected_type:\n",
    "                        mismatches.append({\n",
    "                            'source_id': source_id,\n",
    "                            'end_year': end_year,\n",
    "                            'title': title,\n",
    "                            'name': name,\n",
    "                            'approval_status': matched_approval['status'],\n",
    "                            'expected_type': expected_type,\n",
    "                            'db_type': db_type,\n",
    "                            'action_date': action_date,\n",
    "                            'approval_date': matched_approval['approval_date'],\n",
    "                            'match_type': 'time_matched'\n",
    "                        })\n",
    "                else:\n",
    "                    # ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ - ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ ì°¾ê¸°\n",
    "                    closest = None\n",
    "                    min_diff = float('inf')\n",
    "                    \n",
    "                    for appr in approval_list:\n",
    "                        appr_date = parse_datetime(appr['approval_date'])\n",
    "                        if action_date and appr_date:\n",
    "                            diff = abs((action_date - appr_date).total_seconds())\n",
    "                            if diff < min_diff:\n",
    "                                min_diff = diff\n",
    "                                closest = appr\n",
    "                    \n",
    "                    # ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ê¸°ë¡ (ë³„ë„ ì¹´í…Œê³ ë¦¬)\n",
    "                    mismatches.append({\n",
    "                        'source_id': source_id,\n",
    "                        'end_year': end_year,\n",
    "                        'title': title,\n",
    "                        'name': name,\n",
    "                        'approval_status': f\"[ì—¬ëŸ¬ ê±´: {[a['status'] for a in approval_list]}]\",\n",
    "                        'expected_type': f\"[ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨, ì˜¤ì°¨: {min_diff:.0f}ì´ˆ]\",\n",
    "                        'db_type': db_type,\n",
    "                        'action_date': action_date,\n",
    "                        'approval_date': f\"[{[str(a['approval_date']) for a in approval_list]}]\",\n",
    "                        'match_type': 'time_mismatch'\n",
    "                    })\n",
    "    \n",
    "    print(f'\\nâœ… ê²€ì¦ ì™„ë£Œ')\n",
    "    print(f'   ë§¤ì¹­ ì„±ê³µ: {matched_count}ê±´')\n",
    "    print(f'   ë§¤ì¹­ ì‹¤íŒ¨ (approval_dataì— ì—†ìŒ): {not_found_count}ê±´')\n",
    "    print(f'   ì‹œê°„ìœ¼ë¡œ ë§¤ì¹­ëœ ì¼€ì´ìŠ¤: {time_matched_count}ê±´')\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "# ê²€ì¦ ì‹¤í–‰\n",
    "print('ê²€ì¦ ì‹œì‘...')\n",
    "mismatches = verify_action_types_with_time(documents_df, approval_df, tolerance_seconds=60)\n",
    "print(f'\\nğŸ”´ ë¶ˆì¼ì¹˜ ë°œê²¬: {len(mismatches)}ê±´')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë§¤ì¹­ íƒ€ì…ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:\n",
      "match_type\n",
      "single          48\n",
      "time_matched     2\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š ì—°ë„ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:\n",
      "end_year\n",
      "2010     3\n",
      "2015    25\n",
      "2020    16\n",
      "2025     6\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š ê²°ì¬ìë³„ ë¶ˆì¼ì¹˜ í˜„í™© (ìƒìœ„ 20ëª…):\n",
      "name\n",
      "ì •ì£¼ì—°    12\n",
      "ê¹€ë™ë ¥    10\n",
      "ê¹€ë¯¼ì„œ     5\n",
      "ìµœê¸°ì›     5\n",
      "ê¶Œë¯¼ì„      3\n",
      "ê¹€ì›      3\n",
      "ë°•ìƒíƒ     3\n",
      "ìœ íƒœê²½     3\n",
      "ê¹€ì¬ì›     1\n",
      "ê¹€íƒœì˜     1\n",
      "ìœ¤ë‹¤ì†”     1\n",
      "ì´ì›í•˜     1\n",
      "ì£¼ê´‘ì¼     1\n",
      "í•œìŠ¹ì¬     1\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "ìƒì„¸ ë¶ˆì¼ì¹˜ ëª©ë¡ (ì²˜ìŒ 20ê±´):\n",
      "================================================================================\n",
      "\n",
      "[1] source_id: 2002397 (end_year: 2010)\n",
      "    ì œëª©: AnyFive íšŒì‹ë¹„ ì§€ì› ìš”ì²­\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2010-05-31 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2010-05-31 14:16:34\n",
      "\n",
      "[2] source_id: 2002778 (end_year: 2010)\n",
      "    ì œëª©: ì¶œì¥í’ˆì˜ì„œ\n",
      "    ê²°ì¬ì: ìµœê¸°ì›\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2010-11-16 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2010-11-16 15:36:11\n",
      "\n",
      "[3] source_id: 2002778 (end_year: 2010)\n",
      "    ì œëª©: ì¶œì¥í’ˆì˜ì„œ\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2010-11-16 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2010-11-16 15:12:35\n",
      "\n",
      "[4] source_id: 2003017 (end_year: 2015)\n",
      "    ì œëª©: ì—°ì°¨ì‚¬ìš© í’ˆì˜\n",
      "    ê²°ì¬ì: ìµœê¸°ì›\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2011-02-23 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2011-02-23 18:17:50\n",
      "\n",
      "[5] source_id: 2003144 (end_year: 2015)\n",
      "    ì œëª©: ê¹€í˜„ìˆ™ í‡´ì§ í’ˆì˜\n",
      "    ê²°ì¬ì: ìµœê¸°ì›\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2011-04-14 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2011-04-14 08:55:51\n",
      "\n",
      "[6] source_id: 2003188 (end_year: 2015)\n",
      "    ì œëª©: íœ´ê°€ í’ˆì˜   - ì›ì„±ì¬ ì‚¬ì› -\n",
      "    ê²°ì¬ì: ìµœê¸°ì›\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2011-05-02 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2011-05-02 15:50:37\n",
      "\n",
      "[7] source_id: 2003480 (end_year: 2015)\n",
      "    ì œëª©: ì—°ì°¨ì‚¬ìš© í’ˆì˜ (ê¹€í•˜ì‘_0906)\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2011-09-08 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2011-09-08 09:14:36\n",
      "\n",
      "[8] source_id: 2003628 (end_year: 2015)\n",
      "    ì œëª©: ë…¸íŠ¸ë¶ ì¼€ì´ìŠ¤ êµí™˜ ë¹„ìš© ì²­êµ¬\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2011-11-09 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2011-11-09 18:11:22\n",
      "\n",
      "[9] source_id: 2003778 (end_year: 2015)\n",
      "    ì œëª©: 2011/12ì›” ë²•ì¸ì¹´ë“œ í’ˆì˜\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2012-01-09 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2012-01-09 16:05:44\n",
      "\n",
      "[10] source_id: 2004861 (end_year: 2015)\n",
      "    ì œëª©: (ì´ì§„ê·¼K) ì¶œì‚°íœ´ê°€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2012-11-12 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2012-11-12 09:21:06\n",
      "\n",
      "[11] source_id: 2005958 (end_year: 2015)\n",
      "    ì œëª©: ì—°ì°¨íœ´ê°€ ê²°ì¬í’ˆì˜ì…ë‹ˆë‹¤.\n",
      "    ê²°ì¬ì: ì£¼ê´‘ì¼\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2013-08-07 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2013-08-07 15:20:25\n",
      "\n",
      "[12] source_id: 2006317 (end_year: 2015)\n",
      "    ì œëª©: ì¶œì¥ë¹„ í’ˆì˜ ì˜¬ë¦½ë‹ˆë‹¤\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2013-10-30 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2013-10-30 09:26:46\n",
      "\n",
      "[13] source_id: 2006317 (end_year: 2015)\n",
      "    ì œëª©: ì¶œì¥ë¹„ í’ˆì˜ ì˜¬ë¦½ë‹ˆë‹¤\n",
      "    ê²°ì¬ì: ìµœê¸°ì›\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2013-10-30 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2013-10-30 09:41:22\n",
      "\n",
      "[14] source_id: 2006767 (end_year: 2015)\n",
      "    ì œëª©: ì—°ì°¨íœ´ê°€ ì‹ ì²­(2014/2/04(í™”))\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2014-02-05 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2014-02-05 16:59:44\n",
      "\n",
      "[15] source_id: 2007744 (end_year: 2015)\n",
      "    ì œëª©: LGì „ì TIPISê¸°ëŠ¥ê°œì„  ì™¸ì£¼ì¸ì› íˆ¬ì… í’ˆì˜\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2014-09-25 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2014-09-25 13:16:34\n",
      "\n",
      "[16] source_id: 2007745 (end_year: 2015)\n",
      "    ì œëª©: LGì´ë…¸í… íŠ¹í—ˆì‹œìŠ¤í…œ ê¸°ëŠ¥ê°œì„  ì™¸ì£¼ íˆ¬ì…í’ˆì˜\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2014-09-25 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2014-09-25 11:58:23\n",
      "\n",
      "[17] source_id: 2007761 (end_year: 2015)\n",
      "    ì œëª©: LGì „ì TIPISê¸°ëŠ¥ê°œì„  CPí’ˆì˜\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2014-09-26 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2014-09-26 08:56:08\n",
      "\n",
      "[18] source_id: 2007761 (end_year: 2015)\n",
      "    ì œëª©: LGì „ì TIPISê¸°ëŠ¥ê°œì„  CPí’ˆì˜\n",
      "    ê²°ì¬ì: ê¹€íƒœì˜\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2014-09-26 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2014-09-26 09:15:32\n",
      "\n",
      "[19] source_id: 2008352 (end_year: 2015)\n",
      "    ì œëª©: 2ì›” ì‹ëŒ€ì²­êµ¬\n",
      "    ê²°ì¬ì: ìœ íƒœê²½\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2015-03-26 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2015-03-26 18:23:20\n",
      "\n",
      "[20] source_id: 2008408 (end_year: 2015)\n",
      "    ì œëª©: [ê²°ì œí’ˆì˜]ìƒí‘œì¶œì› (IP Manager)ìˆ˜ìˆ˜ë£Œ ë° ê´€ë‚©ë£Œ ì§€ê¸‰ì˜ ê±´\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    ë§¤ì¹­ íƒ€ì…: single\n",
      "    approval_data: ë°˜ë ¤ â†’ ì˜ˆìƒ: RETURN\n",
      "    documents: APPROVAL âŒ\n",
      "    ì‹œê°„ - activities: 2015-05-08 00:00:00\n",
      "    ì‹œê°„ - approval_data: 2015-05-08 17:05:31\n"
     ]
    }
   ],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    print('ğŸ“Š ë§¤ì¹­ íƒ€ì…ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:')\n",
    "    print(result_df.groupby('match_type').size())\n",
    "    \n",
    "    print('\\nğŸ“Š ì—°ë„ë³„ ë¶ˆì¼ì¹˜ í˜„í™©:')\n",
    "    print(result_df.groupby('end_year').size())\n",
    "    \n",
    "    print('\\nğŸ“Š ê²°ì¬ìë³„ ë¶ˆì¼ì¹˜ í˜„í™© (ìƒìœ„ 20ëª…):')\n",
    "    print(result_df.groupby('name').size().sort_values(ascending=False).head(20))\n",
    "    \n",
    "    # ìƒì„¸ ë‚´ìš© ì¶œë ¥\n",
    "    print('\\n' + '='*80)\n",
    "    print('ìƒì„¸ ë¶ˆì¼ì¹˜ ëª©ë¡ (ì²˜ìŒ 20ê±´):')\n",
    "    print('='*80)\n",
    "    \n",
    "    for i, row in result_df.head(20).iterrows():\n",
    "        print(f\"\\n[{i+1}] source_id: {row['source_id']} (end_year: {row['end_year']})\")\n",
    "        print(f\"    ì œëª©: {row['title'][:50]}...\" if len(str(row['title'])) > 50 else f\"    ì œëª©: {row['title']}\")\n",
    "        print(f\"    ê²°ì¬ì: {row['name']}\")\n",
    "        print(f\"    ë§¤ì¹­ íƒ€ì…: {row['match_type']}\")\n",
    "        print(f\"    approval_data: {row['approval_status']} â†’ ì˜ˆìƒ: {row['expected_type']}\")\n",
    "        print(f\"    documents: {row['db_type']} âŒ\")\n",
    "        print(f\"    ì‹œê°„ - activities: {row['action_date']}\")\n",
    "        print(f\"    ì‹œê°„ - approval_data: {row['approval_date']}\")\n",
    "else:\n",
    "    print('ğŸ‰ ë¶ˆì¼ì¹˜ ì—†ìŒ! ëª¨ë“  actionLogTypeì´ ì •í™•í•©ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    time_mismatch_df = result_df[result_df['match_type'] == 'time_mismatch']\n",
    "    \n",
    "    if len(time_mismatch_df) > 0:\n",
    "        print(f'ğŸ“Š ì‹œê°„ ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤: {len(time_mismatch_df)}ê±´')\n",
    "        print('\\nì´ ì¼€ì´ìŠ¤ë“¤ì€ ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ê²°ì¬í–ˆëŠ”ë° ì‹œê°„ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì…ë‹ˆë‹¤.')\n",
    "        print('tolerance_seconds ê°’ì„ ëŠ˜ë¦¬ë©´ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n')\n",
    "        \n",
    "        for i, row in time_mismatch_df.head(10).iterrows():\n",
    "            print(f\"source_id: {row['source_id']}, ê²°ì¬ì: {row['name']}\")\n",
    "            print(f\"  activities ì‹œê°„: {row['action_date']}\")\n",
    "            print(f\"  approval_data ì‹œê°„ë“¤: {row['approval_date']}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ê²°ê³¼ CSV ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: actionType_ë¶ˆì¼ì¹˜ëª©ë¡_ì‹œê°„ë¹„êµ.csv\n",
      "   ì´ 50ê±´ì˜ ë¶ˆì¼ì¹˜ ë°œê²¬\n"
     ]
    }
   ],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    output_file = 'actionType_ë¶ˆì¼ì¹˜ëª©ë¡_ì‹œê°„ë¹„êµ.csv'\n",
    "    result_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f'âœ… ì €ì¥ ì™„ë£Œ: {output_file}')\n",
    "    print(f'   ì´ {len(result_df)}ê±´ì˜ ë¶ˆì¼ì¹˜ ë°œê²¬')\n",
    "else:\n",
    "    print('ë¶ˆì¼ì¹˜ê°€ ì—†ì–´ì„œ CSVë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. (ì„ íƒ) ë¶ˆì¼ì¹˜ DB ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ë°±ì—…í•˜ì„¸ìš”!\n",
    "UPDATE_DB = False  # Trueë¡œ ë°”ê¾¸ë©´ ì‹¤í–‰ë¨\n",
    "\n",
    "if UPDATE_DB and mismatches:\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    # time_mismatchëŠ” ì œì™¸ (ë¶ˆí™•ì‹¤)\n",
    "    update_df = result_df[result_df['match_type'] != 'time_mismatch']\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    doc_updates = defaultdict(list)\n",
    "    \n",
    "    for _, m in update_df.iterrows():\n",
    "        key = (m['source_id'], m['end_year'])\n",
    "        expected_type = m['expected_type']\n",
    "        if expected_type and not expected_type.startswith('['):\n",
    "            doc_updates[key].append({\n",
    "                'name': m['name'],\n",
    "                'expected_type': expected_type,\n",
    "                'action_date': m['action_date']\n",
    "            })\n",
    "    \n",
    "    updated = 0\n",
    "    \n",
    "    for (source_id, end_year), updates in doc_updates.items():\n",
    "        cursor.execute(\n",
    "            \"SELECT activities FROM documents WHERE source_id = %s AND end_year = %s\",\n",
    "            (source_id, end_year)\n",
    "        )\n",
    "        row = cursor.fetchone()\n",
    "        if not row:\n",
    "            continue\n",
    "        \n",
    "        activities = json.loads(row[0]) if row[0] else []\n",
    "        \n",
    "        modified = False\n",
    "        for upd in updates:\n",
    "            for act in activities:\n",
    "                # ì´ë¦„ê³¼ ì‹œê°„ ë‘˜ ë‹¤ ë§¤ì¹­\n",
    "                if act.get('name') == upd['name']:\n",
    "                    act_date = unix_ms_to_datetime(act.get('actionDate'))\n",
    "                    if times_match(act_date, upd['action_date'], tolerance_seconds=60) or len(updates) == 1:\n",
    "                        act['actionLogType'] = upd['expected_type']\n",
    "                        act['type'] = upd['expected_type']\n",
    "                        modified = True\n",
    "                        break\n",
    "        \n",
    "        if modified:\n",
    "            cursor.execute(\n",
    "                \"UPDATE documents SET activities = %s WHERE source_id = %s AND end_year = %s\",\n",
    "                (json.dumps(activities, ensure_ascii=False), source_id, end_year)\n",
    "            )\n",
    "            updated += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f'âœ… {updated}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ')\n",
    "    print(f'   (time_mismatch ì¼€ì´ìŠ¤ëŠ” ì œì™¸ë¨)')\n",
    "else:\n",
    "    print('UPDATE_DB = Trueë¡œ ì„¤ì •í•˜ë©´ ë¶ˆì¼ì¹˜ê°€ DBì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
