{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê²°ì¬ ëŒ“ê¸€ ê²€ì¦ ë° ì¶”ì¶œ\n",
    "\n",
    "## ëª©ì \n",
    "1. **1ë‹¨ê³„**: DBì— ìˆëŠ” 100ê°œ ëŒ“ê¸€ ê¸°ì¤€ìœ¼ë¡œ HTML íŒŒì‹± ê²€ì¦\n",
    "2. **2ë‹¨ê³„**: ì „ì²´ HTML ìŠ¤ìº” ë° ëˆ„ë½ ëŒ“ê¸€ ì¶”ì¶œ (1ë‹¨ê³„ 100% ì¼ì¹˜ ì‹œ)\n",
    "3. **3ë‹¨ê³„**: DB INSERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì…€ 1: ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)\n",
    "# !pip install beautifulsoup4 lxml mysql-connector-python pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ì„¤ì • ==========\n",
    "\n",
    "# HTML íŒŒì¼ í´ë” ê²½ë¡œ (4ê°œ)\n",
    "HTML_FOLDERS = [\n",
    "    r\"C:\\Users\\LEEJUHWAN\\Downloads\\2010-01-01~2010-12-31\\html\\ê²°ì¬\",\n",
    "    r\"C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html\\ê²°ì¬\",\n",
    "    r\"C:\\Users\\LEEJUHWAN\\Downloads\\2016-01-01~2020-12-31\\html\\ê²°ì¬\",\n",
    "    r\"C:\\Users\\LEEJUHWAN\\Downloads\\2021-01-01~2025-10-31\\html\\ê²°ì¬\",\n",
    "]\n",
    "\n",
    "# DB ì—°ê²° ì •ë³´\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 3306,\n",
    "    'database': 'any_approval',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "print(\"ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"HTML í´ë” ìˆ˜: {len(HTML_FOLDERS)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì…€ 2: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"DB ì—°ê²° ìƒì„±\"\"\"\n",
    "    return mysql.connector.connect(**DB_CONFIG)\n",
    "\n",
    "\n",
    "def extract_doc_id_from_filename(filename):\n",
    "    \"\"\"\n",
    "    íŒŒì¼ëª…ì—ì„œ ë¬¸ì„œë²ˆí˜¸ ì¶”ì¶œ\n",
    "    ì˜ˆ: '20240726_[í•˜ê³„íœ´ê°€ 7_29~30] íœ´ê°€ì‹ ì²­_23447133.html' -> '23447133'\n",
    "    \"\"\"\n",
    "    # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    # ë§ˆì§€ë§‰ ì–¸ë”ìŠ¤ì½”ì–´ ë’¤ì˜ ìˆ«ì ì¶”ì¶œ\n",
    "    match = re.search(r'_(\\d+)$', name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def datetime_to_timestamp_ms(dt_str):\n",
    "    \"\"\"\n",
    "    ë‚ ì§œ ë¬¸ìì—´ì„ Unix timestamp (ë°€ë¦¬ì´ˆ)ë¡œ ë³€í™˜\n",
    "    ì˜ˆ: '2024-07-26 13:54:40' -> 1721969680000\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = datetime.strptime(dt_str.strip(), '%Y-%m-%d %H:%M:%S')\n",
    "        return int(dt.timestamp() * 1000)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def timestamp_ms_to_datetime(ts_ms):\n",
    "    \"\"\"\n",
    "    Unix timestamp (ë°€ë¦¬ì´ˆ)ë¥¼ ë‚ ì§œ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    ì˜ˆ: 1721969680000 -> '2024-07-26 13:54:40'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = datetime.fromtimestamp(ts_ms / 1000)\n",
    "        return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def extract_writer_name(writer_full):\n",
    "    \"\"\"\n",
    "    ì‘ì„±ì ì „ì²´ ë¬¸ìì—´ì—ì„œ ì´ë¦„ë§Œ ì¶”ì¶œ\n",
    "    ì˜ˆ: 'ì„í˜„ì¤€/íŒ€ì¥/DXì‚¬ì—…íŒ€' -> 'ì„í˜„ì¤€'\n",
    "    \"\"\"\n",
    "    if not writer_full:\n",
    "        return ''\n",
    "    writer_full = writer_full.strip()\n",
    "    if '/' in writer_full:\n",
    "        return writer_full.split('/')[0].strip()\n",
    "    return writer_full\n",
    "\n",
    "\n",
    "print(\"ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\n[í…ŒìŠ¤íŠ¸]\")\n",
    "print(f\"ë¬¸ì„œë²ˆí˜¸ ì¶”ì¶œ: {extract_doc_id_from_filename('20240726_[í•˜ê³„íœ´ê°€ 7_29~30] íœ´ê°€ì‹ ì²­_23447133.html')}\")\n",
    "print(f\"ë‚ ì§œâ†’íƒ€ì„ìŠ¤íƒ¬í”„: {datetime_to_timestamp_ms('2024-07-26 13:54:40')}\")\n",
    "print(f\"íƒ€ì„ìŠ¤íƒ¬í”„â†’ë‚ ì§œ: {timestamp_ms_to_datetime(1721969680000)}\")\n",
    "print(f\"ì‘ì„±ì ì¶”ì¶œ: {extract_writer_name('ì„í˜„ì¤€/íŒ€ì¥/DXì‚¬ì—…íŒ€')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì…€ 3: HTML íŒŒì‹± í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_with_linebreaks(element):\n",
    "    \"\"\"\n",
    "    HTML ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (br íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜)\n",
    "    <br>, <br/>, <br /> ëª¨ë‘ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    if element is None:\n",
    "        return ''\n",
    "    \n",
    "    # ë¨¼ì € br íƒœê·¸ë¥¼ íŠ¹ìˆ˜ ë§ˆì»¤ë¡œ ë³€í™˜\n",
    "    for br in element.find_all('br'):\n",
    "        br.replace_with('\\n')\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    text = element.get_text()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def parse_comments_from_html(html_path):\n",
    "    \"\"\"\n",
    "    HTML íŒŒì¼ì—ì„œ ê²°ì¬ëŒ“ê¸€ ì¶”ì¶œ\n",
    "    \n",
    "    Returns:\n",
    "        list of dict: [{'writer': 'ì„í˜„ì¤€', 'created_at': '2024-07-26 13:54:40', 'message': '...'}, ...]\n",
    "        None if error\n",
    "    \"\"\"\n",
    "    comments = []\n",
    "    \n",
    "    try:\n",
    "        # íŒŒì¼ ì½ê¸° (ì¸ì½”ë”© ì²˜ë¦¬)\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            html_content = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(html_path, 'r', encoding='cp949') as f:\n",
    "                html_content = f.read()\n",
    "        except:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    # BeautifulSoupìœ¼ë¡œ íŒŒì‹± (lxml íŒŒì„œ ì‚¬ìš©)\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    \n",
    "    # ê²°ì¬ëŒ“ê¸€ í…Œì´ë¸” ì°¾ê¸°\n",
    "    comment_table = soup.find('table', {'summary': 'ê²°ì¬ëŒ“ê¸€'})\n",
    "    if not comment_table:\n",
    "        return comments  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ëŒ“ê¸€ í…Œì´ë¸” ìì²´ê°€ ì—†ìŒ)\n",
    "    \n",
    "    # td ì•ˆì—ì„œ ëŒ“ê¸€ ì¶”ì¶œ\n",
    "    td = comment_table.find('td')\n",
    "    if not td:\n",
    "        return comments\n",
    "    \n",
    "    # span.F_12_black_b (ì‘ì„±ì)ì™€ span.F_11_gray (ë‚ ì§œ) ìŒì„ ì°¾ê¸°\n",
    "    writer_spans = td.find_all('span', class_='F_12_black_b')\n",
    "    \n",
    "    for writer_span in writer_spans:\n",
    "        comment = {}\n",
    "        \n",
    "        # ì‘ì„±ì ì¶”ì¶œ\n",
    "        writer_full = writer_span.get_text().strip()\n",
    "        comment['writer'] = extract_writer_name(writer_full)\n",
    "        \n",
    "        # ë‚ ì§œ ì¶”ì¶œ (ì‘ì„±ì span ë‹¤ìŒì˜ F_11_gray span)\n",
    "        date_span = writer_span.find_next_sibling('span', class_='F_11_gray')\n",
    "        if date_span:\n",
    "            comment['created_at'] = date_span.get_text().strip()\n",
    "        else:\n",
    "            # ë¶€ëª¨ì—ì„œ ì°¾ê¸°\n",
    "            parent = writer_span.parent\n",
    "            if parent:\n",
    "                date_span = parent.find('span', class_='F_11_gray')\n",
    "                if date_span:\n",
    "                    comment['created_at'] = date_span.get_text().strip()\n",
    "                else:\n",
    "                    comment['created_at'] = ''\n",
    "            else:\n",
    "                comment['created_at'] = ''\n",
    "        \n",
    "        # ëŒ“ê¸€ ë‚´ìš© ì¶”ì¶œ (ì‘ì„±ì span ì´í›„ì˜ div ì•ˆì˜ ë‚´ìš©)\n",
    "        # êµ¬ì¡°: span.user > br > div > (pre ë˜ëŠ” í…ìŠ¤íŠ¸)\n",
    "        message = ''\n",
    "        \n",
    "        # writer_spanì˜ ë¶€ëª¨(span.user)ë¥¼ ì°¾ê³ , ê·¸ ë‹¤ìŒ divë¥¼ ì°¾ê¸°\n",
    "        parent_span = writer_span.parent\n",
    "        if parent_span and parent_span.name == 'span':\n",
    "            # ë‹¤ìŒ í˜•ì œ ìš”ì†Œë“¤ ì¤‘ div ì°¾ê¸°\n",
    "            next_elem = parent_span.next_sibling\n",
    "            while next_elem:\n",
    "                if hasattr(next_elem, 'name') and next_elem.name == 'div':\n",
    "                    # div ì°¾ìŒ, ê·¸ ì•ˆì˜ pre ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                    pre = next_elem.find('pre')\n",
    "                    if pre:\n",
    "                        message = get_text_with_linebreaks(pre)\n",
    "                    else:\n",
    "                        message = get_text_with_linebreaks(next_elem)\n",
    "                    break\n",
    "                next_elem = next_elem.next_sibling\n",
    "        \n",
    "        comment['message'] = message\n",
    "        \n",
    "        # ìœ íš¨í•œ ëŒ“ê¸€ë§Œ ì¶”ê°€ (ì‘ì„±ì ë˜ëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°)\n",
    "        if comment['writer'] or comment['message']:\n",
    "            comments.append(comment)\n",
    "    \n",
    "    return comments\n",
    "\n",
    "\n",
    "print(\"HTML íŒŒì‹± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì…€ 4: HTML íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_html_files():\n",
    "    \"\"\"\n",
    "    ëª¨ë“  í´ë”ì—ì„œ HTML íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘\n",
    "    \n",
    "    Returns:\n",
    "        dict: {ë¬¸ì„œë²ˆí˜¸: íŒŒì¼ê²½ë¡œ}\n",
    "    \"\"\"\n",
    "    html_files = {}\n",
    "    folder_stats = {}\n",
    "    \n",
    "    for folder in HTML_FOLDERS:\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"âš ï¸ í´ë” ì—†ìŒ: {folder}\")\n",
    "            continue\n",
    "        \n",
    "        folder_name = os.path.basename(os.path.dirname(os.path.dirname(folder)))\n",
    "        count = 0\n",
    "        \n",
    "        # í•˜ìœ„ ì—°ë„ í´ë”ë“¤ ìˆœíšŒ\n",
    "        for year_folder in glob.glob(os.path.join(folder, '*')):\n",
    "            if os.path.isdir(year_folder):\n",
    "                for html_file in glob.glob(os.path.join(year_folder, '*.html')):\n",
    "                    doc_id = extract_doc_id_from_filename(os.path.basename(html_file))\n",
    "                    if doc_id:\n",
    "                        html_files[doc_id] = html_file\n",
    "                        count += 1\n",
    "        \n",
    "        folder_stats[folder_name] = count\n",
    "    \n",
    "    return html_files, folder_stats\n",
    "\n",
    "\n",
    "# HTML íŒŒì¼ ìˆ˜ì§‘\n",
    "print(\"HTML íŒŒì¼ ìˆ˜ì§‘ ì¤‘...\")\n",
    "html_files_dict, folder_stats = collect_html_files()\n",
    "\n",
    "print(f\"\\n=== HTML íŒŒì¼ ìŠ¤ìº” ê²°ê³¼ ===\")\n",
    "print(f\"ì´ íŒŒì¼ ìˆ˜: {len(html_files_dict):,}ê°œ\\n\")\n",
    "\n",
    "print(\"í´ë”ë³„:\")\n",
    "for folder_name, count in folder_stats.items():\n",
    "    print(f\"  - {folder_name}: {count:,}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì…€ 5: DB ëŒ“ê¸€ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì—ì„œ ëŒ“ê¸€ ë°ì´í„° ë¡œë“œ\n",
    "conn = get_db_connection()\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    source_id,\n",
    "    source_document_id,\n",
    "    created_at,\n",
    "    updated_at,\n",
    "    writer,\n",
    "    message\n",
    "FROM comments\n",
    "ORDER BY source_document_id, created_at\n",
    "\"\"\"\n",
    "\n",
    "db_comments_df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€ (ì½ê¸° ì‰½ê²Œ)\n",
    "db_comments_df['created_at_str'] = db_comments_df['created_at'].apply(timestamp_ms_to_datetime)\n",
    "\n",
    "print(f\"=== DB comments í…Œì´ë¸” í˜„í™© ===\")\n",
    "print(f\"ì´ ë ˆì½”ë“œ: {len(db_comments_df)}ê°œ\")\n",
    "print(f\"ë¬¸ì„œ ìˆ˜: {db_comments_df['source_document_id'].nunique()}ê°œ (ì¤‘ë³µ ì œì™¸)\")\n",
    "\n",
    "# ì¤‘ë³µ ì²´í¬ (source_id ê¸°ì¤€)\n",
    "duplicate_source_ids = db_comments_df[db_comments_df.duplicated(subset=['source_id'], keep=False)]\n",
    "if len(duplicate_source_ids) > 0:\n",
    "    print(f\"\\nâš ï¸ source_id ì¤‘ë³µ ë ˆì½”ë“œ ë°œê²¬: {len(duplicate_source_ids)}ê±´\")\n",
    "    print(duplicate_source_ids[['source_id', 'writer', 'created_at_str', 'message']].head(10))\n",
    "else:\n",
    "    print(f\"\\nâœ… source_id ì¤‘ë³µ ì—†ìŒ\")\n",
    "\n",
    "# ì—°ë„ë³„ í†µê³„\n",
    "db_comments_df['year'] = pd.to_datetime(db_comments_df['created_at_str']).dt.year\n",
    "print(f\"\\nì—°ë„ë³„:\")\n",
    "year_counts = db_comments_df.groupby('year').size()\n",
    "for year, count in year_counts.items():\n",
    "    print(f\"  - {year}: {count}ê°œ\")\n",
    "\n",
    "print(f\"\\nê¸°ê°„: {db_comments_df['created_at_str'].min()} ~ {db_comments_df['created_at_str'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB ëŒ“ê¸€ ìƒ˜í”Œ í™•ì¸\n",
    "print(\"=== DB ëŒ“ê¸€ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ) ===\")\n",
    "db_comments_df[['source_document_id', 'writer', 'created_at_str', 'message']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ” 1ë‹¨ê³„: DB ëŒ“ê¸€ ê¸°ì¤€ HTML íŒŒì‹± ê²€ì¦\n",
    "\n",
    "DBì— ìˆëŠ” 100ê°œ ëŒ“ê¸€ì„ HTMLì—ì„œ íŒŒì‹±í•œ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ íŒŒì‹± ë¡œì§ì´ ì •í™•í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì— ìˆëŠ” ëŒ“ê¸€ì˜ ë¬¸ì„œë²ˆí˜¸ ëª©ë¡\n",
    "db_doc_ids = db_comments_df['source_document_id'].unique().tolist()\n",
    "print(f\"DBì— ìˆëŠ” ë¬¸ì„œë²ˆí˜¸: {len(db_doc_ids)}ê°œ\")\n",
    "\n",
    "# HTML íŒŒì¼ì´ ìˆëŠ” ë¬¸ì„œë²ˆí˜¸ í•„í„°ë§\n",
    "db_doc_ids_with_html = [doc_id for doc_id in db_doc_ids if doc_id in html_files_dict]\n",
    "db_doc_ids_without_html = [doc_id for doc_id in db_doc_ids if doc_id not in html_files_dict]\n",
    "\n",
    "print(f\"HTML íŒŒì¼ ìˆëŠ” ë¬¸ì„œ: {len(db_doc_ids_with_html)}ê°œ\")\n",
    "print(f\"HTML íŒŒì¼ ì—†ëŠ” ë¬¸ì„œ: {len(db_doc_ids_without_html)}ê°œ\")\n",
    "\n",
    "if db_doc_ids_without_html:\n",
    "    print(f\"\\nğŸ“‹ HTML íŒŒì¼ ì—†ëŠ” ë¬¸ì„œ ëª©ë¡ (DBì— ìˆì§€ë§Œ HTML ì—†ìŒ):\")\n",
    "    for doc_id in db_doc_ids_without_html:\n",
    "        doc_comments = db_comments_df[db_comments_df['source_document_id'] == doc_id]\n",
    "        for _, row in doc_comments.iterrows():\n",
    "            print(f\"  - ë¬¸ì„œë²ˆí˜¸: {doc_id}, ì‘ì„±ì¼: {row['created_at_str']}, ì‘ì„±ì: {row['writer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLì—ì„œ ëŒ“ê¸€ íŒŒì‹± ë° DBì™€ ë¹„êµ\n",
    "print(\"=== HTML íŒŒì‹± ê²€ì¦ ì‹œì‘ ===\")\n",
    "print(f\"ê²€ì¦ ëŒ€ìƒ: {len(db_doc_ids_with_html)}ê°œ ë¬¸ì„œ\\n\")\n",
    "\n",
    "validation_results = []\n",
    "parse_errors = []\n",
    "\n",
    "for doc_id in tqdm(db_doc_ids_with_html, desc=\"HTML íŒŒì‹± ì¤‘\"):\n",
    "    html_path = html_files_dict[doc_id]\n",
    "    \n",
    "    # HTMLì—ì„œ ëŒ“ê¸€ íŒŒì‹±\n",
    "    html_comments = parse_comments_from_html(html_path)\n",
    "    \n",
    "    if html_comments is None:\n",
    "        parse_errors.append({'doc_id': doc_id, 'error': 'íŒŒì¼ ì½ê¸° ì‹¤íŒ¨', 'path': html_path})\n",
    "        continue\n",
    "    \n",
    "    # DBì—ì„œ í•´ë‹¹ ë¬¸ì„œì˜ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°\n",
    "    db_doc_comments = db_comments_df[db_comments_df['source_document_id'] == doc_id].copy()\n",
    "    \n",
    "    # ë¹„êµ\n",
    "    for idx, db_row in db_doc_comments.iterrows():\n",
    "        result = {\n",
    "            'doc_id': doc_id,\n",
    "            'db_writer': db_row['writer'],\n",
    "            'db_created_at': db_row['created_at_str'],\n",
    "            'db_message': db_row['message'],\n",
    "            'html_writer': None,\n",
    "            'html_created_at': None,\n",
    "            'html_message': None,\n",
    "            'match_status': 'NOT_FOUND',\n",
    "            'detail': ''\n",
    "        }\n",
    "        \n",
    "        # HTML ëŒ“ê¸€ì—ì„œ ë§¤ì¹­ë˜ëŠ” ê²ƒ ì°¾ê¸° (ì‘ì„±ì + ë‚ ì§œ ê¸°ì¤€)\n",
    "        for html_comment in html_comments:\n",
    "            if (html_comment['writer'] == db_row['writer'] and \n",
    "                html_comment['created_at'] == db_row['created_at_str']):\n",
    "                \n",
    "                result['html_writer'] = html_comment['writer']\n",
    "                result['html_created_at'] = html_comment['created_at']\n",
    "                result['html_message'] = html_comment['message']\n",
    "                \n",
    "                # ë‚´ìš© ë¹„êµ\n",
    "                db_msg = (db_row['message'] or '').strip()\n",
    "                html_msg = (html_comment['message'] or '').strip()\n",
    "                \n",
    "                if db_msg == html_msg:\n",
    "                    result['match_status'] = 'EXACT_MATCH'\n",
    "                elif db_msg.replace('\\r\\n', '\\n') == html_msg.replace('\\r\\n', '\\n'):\n",
    "                    result['match_status'] = 'MATCH_CRLF_DIFF'\n",
    "                    result['detail'] = 'ì¤„ë°”ê¿ˆ ë¬¸ì ì°¨ì´ (\\\\r\\\\n vs \\\\n)'\n",
    "                elif db_msg.replace(' ', '').replace('\\n', '') == html_msg.replace(' ', '').replace('\\n', ''):\n",
    "                    result['match_status'] = 'MATCH_WHITESPACE_DIFF'\n",
    "                    result['detail'] = 'ê³µë°±/ì¤„ë°”ê¿ˆ ì°¨ì´'\n",
    "                else:\n",
    "                    result['match_status'] = 'CONTENT_MISMATCH'\n",
    "                    result['detail'] = f'DBê¸¸ì´:{len(db_msg)}, HTMLê¸¸ì´:{len(html_msg)}'\n",
    "                break\n",
    "        \n",
    "        validation_results.append(result)\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "print(f\"\\nê²€ì¦ ì™„ë£Œ: {len(validation_df)}ê°œ ëŒ“ê¸€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦ ê²°ê³¼ ìš”ì•½\n",
    "print(\"=== íŒŒì‹± ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "\n",
    "status_counts = validation_df['match_status'].value_counts()\n",
    "total = len(validation_df)\n",
    "\n",
    "for status, count in status_counts.items():\n",
    "    pct = count / total * 100\n",
    "    if status == 'EXACT_MATCH':\n",
    "        print(f\"  âœ… ì™„ì „ ì¼ì¹˜: {count}ê°œ ({pct:.1f}%)\")\n",
    "    elif status == 'MATCH_CRLF_DIFF':\n",
    "        print(f\"  âš ï¸ ì¤„ë°”ê¿ˆ ë¬¸ì ì°¨ì´ë§Œ ìˆìŒ: {count}ê°œ ({pct:.1f}%)\")\n",
    "    elif status == 'MATCH_WHITESPACE_DIFF':\n",
    "        print(f\"  âš ï¸ ê³µë°±/ì¤„ë°”ê¿ˆ ì°¨ì´ë§Œ ìˆìŒ: {count}ê°œ ({pct:.1f}%)\")\n",
    "    elif status == 'CONTENT_MISMATCH':\n",
    "        print(f\"  âŒ ë‚´ìš© ë¶ˆì¼ì¹˜: {count}ê°œ ({pct:.1f}%)\")\n",
    "    elif status == 'NOT_FOUND':\n",
    "        print(f\"  â“ HTMLì—ì„œ ëª» ì°¾ìŒ: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "if parse_errors:\n",
    "    print(f\"\\nâš ï¸ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {len(parse_errors)}ê±´\")\n",
    "    for err in parse_errors:\n",
    "        print(f\"  - ë¬¸ì„œë²ˆí˜¸: {err['doc_id']}, ì˜¤ë¥˜: {err['error']}\")\n",
    "\n",
    "# ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "match_count = len(validation_df[validation_df['match_status'].isin(['EXACT_MATCH', 'MATCH_CRLF_DIFF', 'MATCH_WHITESPACE_DIFF'])])\n",
    "match_rate = match_count / total * 100 if total > 0 else 0\n",
    "print(f\"\\nğŸ“Š ì „ì²´ ì¼ì¹˜ìœ¨: {match_rate:.1f}% ({match_count}/{total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶ˆì¼ì¹˜/ë¯¸ë°œê²¬ ì¼€ì´ìŠ¤ ìƒì„¸ í™•ì¸\n",
    "problem_cases = validation_df[~validation_df['match_status'].isin(['EXACT_MATCH', 'MATCH_CRLF_DIFF'])]\n",
    "\n",
    "if len(problem_cases) > 0:\n",
    "    print(f\"=== ë¶ˆì¼ì¹˜/ë¯¸ë°œê²¬ ì¼€ì´ìŠ¤ ìƒì„¸ ({len(problem_cases)}ê±´) ===\")\n",
    "    \n",
    "    for idx, row in problem_cases.iterrows():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[ë¬¸ì„œë²ˆí˜¸: {row['doc_id']}] ìƒíƒœ: {row['match_status']}\")\n",
    "        print(f\"ìƒì„¸: {row['detail']}\")\n",
    "        print(f\"\\nDB ëŒ“ê¸€:\")\n",
    "        print(f\"  ì‘ì„±ì: {row['db_writer']}\")\n",
    "        print(f\"  ë‚ ì§œ: {row['db_created_at']}\")\n",
    "        print(f\"  ë‚´ìš©: {repr(row['db_message'][:200] if row['db_message'] else '')}...\")\n",
    "        print(f\"\\nHTML ëŒ“ê¸€:\")\n",
    "        print(f\"  ì‘ì„±ì: {row['html_writer']}\")\n",
    "        print(f\"  ë‚ ì§œ: {row['html_created_at']}\")\n",
    "        print(f\"  ë‚´ìš©: {repr(row['html_message'][:200] if row['html_message'] else '')}...\")\n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  ëŒ“ê¸€ì´ ì •ìƒì ìœ¼ë¡œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ë‹¨ê³„ ê²€ì¦ ê²°ë¡ \n",
    "exact_match_count = len(validation_df[validation_df['match_status'] == 'EXACT_MATCH'])\n",
    "acceptable_match_count = len(validation_df[validation_df['match_status'].isin(['EXACT_MATCH', 'MATCH_CRLF_DIFF'])])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"1ë‹¨ê³„ ê²€ì¦ ê²°ë¡ \")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if exact_match_count == total:\n",
    "    print(f\"\\nğŸ‰ ì™„ë²½! ëª¨ë“  ëŒ“ê¸€({total}ê°œ)ì´ 100% ì™„ì „ ì¼ì¹˜í•©ë‹ˆë‹¤.\")\n",
    "    print(\"\\nâ†’ 2ë‹¨ê³„ (ì „ì²´ HTML ìŠ¤ìº”)ë¥¼ ì§„í–‰í•´ë„ ë©ë‹ˆë‹¤.\")\n",
    "    VALIDATION_PASSED = True\n",
    "elif acceptable_match_count == total:\n",
    "    print(f\"\\nâœ… ëª¨ë“  ëŒ“ê¸€({total}ê°œ)ì´ ì¼ì¹˜í•©ë‹ˆë‹¤. (ì¼ë¶€ ì¤„ë°”ê¿ˆ ë¬¸ì ì°¨ì´ ìˆìŒ)\")\n",
    "    print(\"\\nâ†’ 2ë‹¨ê³„ (ì „ì²´ HTML ìŠ¤ìº”)ë¥¼ ì§„í–‰í•´ë„ ë©ë‹ˆë‹¤.\")\n",
    "    VALIDATION_PASSED = True\n",
    "else:\n",
    "    problem_count = total - acceptable_match_count\n",
    "    print(f\"\\nâš ï¸ {problem_count}ê°œ ëŒ“ê¸€ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\nâ†’ ìœ„ì˜ ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  íŒŒì‹± ë¡œì§ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "    VALIDATION_PASSED = False\n",
    "\n",
    "print(f\"\\nVALIDATION_PASSED = {VALIDATION_PASSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“‚ 2ë‹¨ê³„: ì „ì²´ HTML ìŠ¤ìº” ë° ëˆ„ë½ ëŒ“ê¸€ ì¶”ì¶œ\n",
    "\n",
    "âš ï¸ **1ë‹¨ê³„ ê²€ì¦ì´ í†µê³¼í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦ í†µê³¼ ì—¬ë¶€ í™•ì¸\n",
    "if not VALIDATION_PASSED:\n",
    "    print(\"âŒ 1ë‹¨ê³„ ê²€ì¦ì´ í†µê³¼í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"íŒŒì‹± ë¡œì§ì„ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âœ… 1ë‹¨ê³„ ê²€ì¦ í†µê³¼! 2ë‹¨ê³„ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ HTML íŒŒì¼ì—ì„œ ëŒ“ê¸€ ì¶”ì¶œ\n",
    "if VALIDATION_PASSED:\n",
    "    print(\"=== ì „ì²´ HTML íŒŒì¼ ìŠ¤ìº” ì‹œì‘ ===\")\n",
    "    print(f\"ìŠ¤ìº” ëŒ€ìƒ: {len(html_files_dict):,}ê°œ íŒŒì¼\\n\")\n",
    "    \n",
    "    all_html_comments = {}  # {doc_id: [comments]}\n",
    "    files_with_comments = 0\n",
    "    files_without_comments = 0\n",
    "    scan_errors = []\n",
    "    year_stats = defaultdict(lambda: {'total': 0, 'with_comments': 0, 'comment_count': 0})\n",
    "    \n",
    "    for doc_id, html_path in tqdm(html_files_dict.items(), desc=\"HTML ìŠ¤ìº” ì¤‘\"):\n",
    "        # ì—°ë„ ì¶”ì¶œ (íŒŒì¼ ê²½ë¡œì—ì„œ)\n",
    "        year_match = re.search(r'\\\\(\\d{4})\\\\', html_path)\n",
    "        year = year_match.group(1) if year_match else 'unknown'\n",
    "        year_stats[year]['total'] += 1\n",
    "        \n",
    "        # HTML íŒŒì‹±\n",
    "        comments = parse_comments_from_html(html_path)\n",
    "        \n",
    "        if comments is None:\n",
    "            scan_errors.append({'doc_id': doc_id, 'path': html_path})\n",
    "            continue\n",
    "        \n",
    "        if comments:\n",
    "            all_html_comments[doc_id] = comments\n",
    "            files_with_comments += 1\n",
    "            year_stats[year]['with_comments'] += 1\n",
    "            year_stats[year]['comment_count'] += len(comments)\n",
    "        else:\n",
    "            files_without_comments += 1\n",
    "    \n",
    "    total_comments = sum(len(c) for c in all_html_comments.values())\n",
    "    \n",
    "    print(f\"\\n=== HTML ìŠ¤ìº” ê²°ê³¼ ===\")\n",
    "    print(f\"ì´ HTML íŒŒì¼: {len(html_files_dict):,}ê°œ\")\n",
    "    print(f\"â”œâ”€ ëŒ“ê¸€ ìˆëŠ” íŒŒì¼: {files_with_comments:,}ê°œ ({files_with_comments/len(html_files_dict)*100:.1f}%)\")\n",
    "    print(f\"â””â”€ ëŒ“ê¸€ ì—†ëŠ” íŒŒì¼: {files_without_comments:,}ê°œ ({files_without_comments/len(html_files_dict)*100:.1f}%)\")\n",
    "    print(f\"\\nì´ ì¶”ì¶œëœ ëŒ“ê¸€ ìˆ˜: {total_comments:,}ê°œ\")\n",
    "    \n",
    "    if scan_errors:\n",
    "        print(f\"\\nâš ï¸ ìŠ¤ìº” ì˜¤ë¥˜: {len(scan_errors)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ë„ë³„ ëŒ“ê¸€ í˜„í™©\n",
    "if VALIDATION_PASSED:\n",
    "    print(\"=== ì—°ë„ë³„ ëŒ“ê¸€ í˜„í™© ===\")\n",
    "    print(f\"{'ì—°ë„':<6} {'ì´íŒŒì¼':>10} {'ëŒ“ê¸€ìˆìŒ':>10} {'ë¹„ìœ¨':>8} {'ëŒ“ê¸€ìˆ˜':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for year in sorted(year_stats.keys()):\n",
    "        stats = year_stats[year]\n",
    "        rate = stats['with_comments'] / stats['total'] * 100 if stats['total'] > 0 else 0\n",
    "        print(f\"{year:<6} {stats['total']:>10,} {stats['with_comments']:>10,} {rate:>7.1f}% {stats['comment_count']:>10,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì™€ ë¹„êµí•˜ì—¬ ëˆ„ë½ ëŒ“ê¸€ ì°¾ê¸°\n",
    "if VALIDATION_PASSED:\n",
    "    print(\"=== DBì™€ HTML ë¹„êµ ===\")\n",
    "    \n",
    "    # HTMLì—ì„œ ì¶”ì¶œí•œ ë¬¸ì„œë²ˆí˜¸\n",
    "    html_doc_ids_with_comments = set(all_html_comments.keys())\n",
    "    \n",
    "    # DBì— ìˆëŠ” ë¬¸ì„œë²ˆí˜¸\n",
    "    db_doc_ids_set = set(db_comments_df['source_document_id'].unique())\n",
    "    \n",
    "    # ë¹„êµ\n",
    "    both = html_doc_ids_with_comments & db_doc_ids_set\n",
    "    html_only = html_doc_ids_with_comments - db_doc_ids_set\n",
    "    db_only = db_doc_ids_set - html_doc_ids_with_comments\n",
    "    \n",
    "    print(f\"\\n[ë¬¸ì„œ ë‹¨ìœ„ ë¹„êµ]\")\n",
    "    print(f\"HTMLì—ì„œ ëŒ“ê¸€ ìˆëŠ” ë¬¸ì„œ: {len(html_doc_ids_with_comments):,}ê°œ\")\n",
    "    print(f\"DBì— ìˆëŠ” ë¬¸ì„œ: {len(db_doc_ids_set)}ê°œ\")\n",
    "    print(f\"â”œâ”€ êµì§‘í•© (ë‘˜ ë‹¤ ìˆìŒ): {len(both)}ê°œ\")\n",
    "    print(f\"â”œâ”€ HTMLì—ë§Œ ìˆìŒ (DB ëˆ„ë½): {len(html_only):,}ê°œ  â† INSERT ëŒ€ìƒ\")\n",
    "    print(f\"â””â”€ DBì—ë§Œ ìˆìŒ (HTMLì— ì—†ìŒ): {len(db_only)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì—ë§Œ ìˆëŠ” ëŒ“ê¸€ ìƒì„¸ (í™•ì¸ìš©)\n",
    "if VALIDATION_PASSED and db_only:\n",
    "    print(\"=== DBì— ìˆì§€ë§Œ HTMLì— ì—†ëŠ” ëŒ“ê¸€ (í™•ì¸ìš©) ===\")\n",
    "    print(f\"ì´ {len(db_only)}ê°œ ë¬¸ì„œ\\n\")\n",
    "    \n",
    "    db_only_comments = db_comments_df[db_comments_df['source_document_id'].isin(db_only)]\n",
    "    print(f\"{'ë¬¸ì„œë²ˆí˜¸':<12} {'ì‘ì„±ì¼':<20} {'ì‘ì„±ì':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    for _, row in db_only_comments.iterrows():\n",
    "        print(f\"{row['source_document_id']:<12} {row['created_at_str']:<20} {row['writer']:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëˆ„ë½ ëŒ“ê¸€ ë°ì´í„° ì¤€ë¹„ (INSERT ëŒ€ìƒ)\n",
    "if VALIDATION_PASSED:\n",
    "    print(\"=== INSERT ëŒ€ìƒ ë°ì´í„° ì¤€ë¹„ ===\")\n",
    "    \n",
    "    missing_comments = []\n",
    "    \n",
    "    for doc_id in html_only:\n",
    "        comments = all_html_comments[doc_id]\n",
    "        \n",
    "        for idx, comment in enumerate(comments, 1):\n",
    "            # source_id ìƒì„±: ìˆœë²ˆ_ë¬¸ì„œë²ˆí˜¸_01\n",
    "            source_id = f\"{idx:02d}_{doc_id}_01\"\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜\n",
    "            created_at_ms = datetime_to_timestamp_ms(comment['created_at'])\n",
    "            \n",
    "            missing_comments.append({\n",
    "                'source_id': source_id,\n",
    "                'source_document_id': doc_id,\n",
    "                'created_at': created_at_ms,\n",
    "                'updated_at': created_at_ms,\n",
    "                'writer': comment['writer'],\n",
    "                'message': comment['message'],\n",
    "                'created_at_str': comment['created_at']  # í™•ì¸ìš©\n",
    "            })\n",
    "    \n",
    "    missing_df = pd.DataFrame(missing_comments)\n",
    "    \n",
    "    print(f\"ì´ {len(html_only):,}ê°œ ë¬¸ì„œì—ì„œ {len(missing_df):,}ê°œ ëŒ“ê¸€\")\n",
    "    \n",
    "    # ì—°ë„ë³„ ëˆ„ë½ í˜„í™©\n",
    "    if len(missing_df) > 0:\n",
    "        missing_df['year'] = pd.to_datetime(missing_df['created_at_str'], errors='coerce').dt.year\n",
    "        print(f\"\\nì—°ë„ë³„ ëˆ„ë½ í˜„í™©:\")\n",
    "        year_missing = missing_df.groupby('year').size()\n",
    "        for year, count in year_missing.items():\n",
    "            print(f\"  - {int(year) if pd.notna(year) else 'N/A'}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëˆ„ë½ ëŒ“ê¸€ ìƒ˜í”Œ í™•ì¸\n",
    "if VALIDATION_PASSED and len(missing_df) > 0:\n",
    "    print(\"=== ëˆ„ë½ ëŒ“ê¸€ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ) ===\")\n",
    "    display(missing_df[['source_id', 'source_document_id', 'created_at_str', 'writer', 'message']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ë¡œ ì €ì¥ (ë°±ì—…ìš©)\n",
    "if VALIDATION_PASSED and len(missing_df) > 0:\n",
    "    csv_path = 'missing_comments.csv'\n",
    "    missing_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "    print(f\"   ì´ {len(missing_df):,}ê°œ ë ˆì½”ë“œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ’¾ 3ë‹¨ê³„: DB INSERT\n",
    "\n",
    "âš ï¸ **ì‹ ì¤‘í•˜ê²Œ ì‹¤í–‰í•˜ì„¸ìš”! ì‹¤í–‰ ì „ ìœ„ì˜ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT ì „ ìµœì¢… í™•ì¸\n",
    "if VALIDATION_PASSED and len(missing_df) > 0:\n",
    "    print(\"=== INSERT ì „ ìµœì¢… í™•ì¸ ===\")\n",
    "    print(f\"INSERT ëŒ€ìƒ: {len(missing_df):,}ê°œ ëŒ“ê¸€\")\n",
    "    print(f\"\\nâš ï¸ ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ DBì— ë°ì´í„°ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.\")\n",
    "    print(f\"   ì‹¤í–‰ ì „ ìœ„ì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"INSERTí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB INSERT ì‹¤í–‰\n",
    "# âš ï¸ ì£¼ì˜: ì´ ì…€ì€ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”!\n",
    "\n",
    "DO_INSERT = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ì‹¤í–‰ë¨\n",
    "\n",
    "if DO_INSERT and VALIDATION_PASSED and len(missing_df) > 0:\n",
    "    print(\"=== DB INSERT ì‹œì‘ ===\")\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO comments (source_id, source_document_id, created_at, updated_at, writer, message)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    success_count = 0\n",
    "    skip_count = 0\n",
    "    error_count = 0\n",
    "    errors = []\n",
    "    \n",
    "    for _, row in tqdm(missing_df.iterrows(), total=len(missing_df), desc=\"INSERT ì¤‘\"):\n",
    "        try:\n",
    "            cursor.execute(insert_query, (\n",
    "                row['source_id'],\n",
    "                row['source_document_id'],\n",
    "                row['created_at'],\n",
    "                row['updated_at'],\n",
    "                row['writer'],\n",
    "                row['message']\n",
    "            ))\n",
    "            success_count += 1\n",
    "        except mysql.connector.IntegrityError as e:\n",
    "            # source_id ì¤‘ë³µ (ì´ë¯¸ ì¡´ì¬)\n",
    "            skip_count += 1\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            errors.append({'source_id': row['source_id'], 'error': str(e)})\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\n=== INSERT ê²°ê³¼ ===\")\n",
    "    print(f\"âœ… ì„±ê³µ: {success_count:,}ê°œ\")\n",
    "    print(f\"â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: {skip_count}ê°œ\")\n",
    "    print(f\"âŒ ì‹¤íŒ¨: {error_count}ê°œ\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\nì˜¤ë¥˜ ìƒì„¸:\")\n",
    "        for err in errors[:10]:\n",
    "            print(f\"  - {err['source_id']}: {err['error']}\")\n",
    "else:\n",
    "    if not DO_INSERT:\n",
    "        print(\"DO_INSERT = False ì…ë‹ˆë‹¤.\")\n",
    "        print(\"INSERTë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ìœ„ì—ì„œ DO_INSERT = True ë¡œ ë³€ê²½í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT í›„ í™•ì¸\n",
    "if DO_INSERT and VALIDATION_PASSED:\n",
    "    conn = get_db_connection()\n",
    "    query = \"SELECT COUNT(*) as cnt FROM comments\"\n",
    "    result = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"=== INSERT í›„ DB í˜„í™© ===\")\n",
    "    print(f\"comments í…Œì´ë¸” ì´ ë ˆì½”ë“œ: {result['cnt'].values[0]:,}ê°œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
