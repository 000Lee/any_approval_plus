{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actionComment ëˆ„ë½ ê²€ì¦\n",
    "HTML ì›ë³¸ê³¼ DBë¥¼ ë¹„êµí•´ì„œ ì§„ì§œ ëˆ„ë½ì¸ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# í´ë” ì„¤ì • (í´ë”ëª… â†’ end_year ë§¤í•‘)\n",
    "BASE_DIR = r'C:\\Users\\LEEJUHWAN\\Downloads'\n",
    "\n",
    "FOLDER_MAPPING = {\n",
    "    '2010-01-01~2010-12-31': 2010,\n",
    "    '2011-01-01~2015-12-31': 2015,\n",
    "    '2016-01-01~2020-12-31': 2020,\n",
    "    '2021-01-01~2025-10-31': 2025\n",
    "}\n",
    "\n",
    "# DB ì„¤ì •\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'database': 'any_approval',\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "print('ì„¤ì • ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HTML íŒŒì‹± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def extract_source_id(filename):\n",
    "    \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì(source_id) ì¶”ì¶œ\"\"\"\n",
    "    numbers = re.findall(r'\\d+', filename)\n",
    "    return numbers[-1] if numbers else None\n",
    "\n",
    "def extract_name_from_text(text):\n",
    "    \"\"\"'ì´ë¦„/ì§ì±…/ë¶€ì„œ' í˜•ì‹ì—ì„œ ì´ë¦„ë§Œ ì¶”ì¶œ\"\"\"\n",
    "    text = re.sub(r'\\d+', '', text).strip()\n",
    "    parts = text.split('/')\n",
    "    return parts[0].strip() if parts else None\n",
    "\n",
    "def parse_html_comments(html_path):\n",
    "    \"\"\"\n",
    "    HTMLì—ì„œ ê²°ì¬ì˜ê²¬ ì¶”ì¶œ\n",
    "    ë°˜í™˜: [(ì´ë¦„, ì˜ê²¬), ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'lxml')  # lxml íŒŒì„œ ì‚¬ìš©\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "    \n",
    "    comments = []\n",
    "    \n",
    "    opinion_th = soup.find('th', string=lambda s: s and 'ê²°ì¬ì˜ê²¬' in s)\n",
    "    if not opinion_th:\n",
    "        return comments, None\n",
    "    \n",
    "    opinion_td = opinion_th.find_next_sibling('td')\n",
    "    if not opinion_td:\n",
    "        return comments, None\n",
    "    \n",
    "    user_spans = opinion_td.find_all('span', class_='user')\n",
    "    \n",
    "    for i, user_span in enumerate(user_spans):\n",
    "        name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "        if not name_elem:\n",
    "            continue\n",
    "        \n",
    "        name = extract_name_from_text(name_elem.get_text(strip=True))\n",
    "        if not name:\n",
    "            continue\n",
    "        \n",
    "        # user_span ë°”ë¡œ ë‹¤ìŒì˜ div ì°¾ê¸°\n",
    "        action_comment = \"\"\n",
    "        next_div = user_span.find_next('div')\n",
    "        \n",
    "        if next_div:\n",
    "            # ë‹¤ìŒ user_spanì´ ìˆìœ¼ë©´ ê·¸ ì „ê¹Œì§€ë§Œ\n",
    "            next_user = user_spans[i + 1] if i + 1 < len(user_spans) else None\n",
    "            \n",
    "            if next_user:\n",
    "                # next_divê°€ next_userë³´ë‹¤ ì•ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "                # (next_divê°€ í˜„ì¬ userì™€ ë‹¤ìŒ user ì‚¬ì´ì— ìˆì–´ì•¼ í•¨)\n",
    "                div_pos = str(opinion_td).find(str(next_div))\n",
    "                user_pos = str(opinion_td).find(str(next_user))\n",
    "                if div_pos < user_pos:\n",
    "                    action_comment = next_div.get_text(strip=True)\n",
    "            else:\n",
    "                # ë§ˆì§€ë§‰ userë©´ ê·¸ëƒ¥ ë‹¤ìŒ div ì‚¬ìš©\n",
    "                action_comment = next_div.get_text(strip=True)\n",
    "        \n",
    "        comments.append((name, action_comment))\n",
    "    \n",
    "    return comments, None\n",
    "\n",
    "print('í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì‹± ê²°ê³¼: [('ìœ íƒœê²½', 'ìœ ë¹„ë³´ìˆ˜ ê³„ì•½ì„œìƒì˜ ì„œë¹„ìŠ¤ ë‚´ìš©ì— ëŒ€í•´ ê²€í† ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.'), ('ë°•ìƒíƒ', 'ì„œë¹„ìŠ¤ ë²”ìœ„ ë° ë³„ì²¨ì˜ ì„œë¹„ìŠ¤ë‚´ìš© ìˆ˜ì •í•´ì£¼ì„¸ìš”..')]\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "html_path = html_index['2008637'][0]\n",
    "comments, error = parse_html_comments(html_path)\n",
    "print(f'íŒŒì‹± ê²°ê³¼: {comments}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HTML íŒŒì¼ ì¸ë±ìŠ¤ ìƒì„±\n",
    "source_id â†’ íŒŒì¼ê²½ë¡œ ë§¤í•‘ (ë¹ ë¥¸ ê²€ìƒ‰ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML íŒŒì¼ ìŠ¤ìº” ì¤‘...\n",
      "ğŸ“ 2010-01-01~2010-12-31 (end_year=2010): 840ê°œ íŒŒì¼\n",
      "ğŸ“ 2011-01-01~2015-12-31 (end_year=2015): 6587ê°œ íŒŒì¼\n",
      "ğŸ“ 2016-01-01~2020-12-31 (end_year=2020): 7704ê°œ íŒŒì¼\n",
      "ğŸ“ 2021-01-01~2025-10-31 (end_year=2025): 8175ê°œ íŒŒì¼\n",
      "\n",
      "âœ… ì´ 23306ê°œ HTML íŒŒì¼ ì¸ë±ì‹± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def build_html_index():\n",
    "    \"\"\"\n",
    "    ëª¨ë“  HTML íŒŒì¼ ìŠ¤ìº”í•´ì„œ source_id â†’ (íŒŒì¼ê²½ë¡œ, end_year) ë§¤í•‘ ìƒì„±\n",
    "    \"\"\"\n",
    "    html_index = {}  # {source_id: (íŒŒì¼ê²½ë¡œ, end_year)}\n",
    "    \n",
    "    for folder_name, end_year in FOLDER_MAPPING.items():\n",
    "        folder_path = Path(BASE_DIR) / folder_name / 'html' / 'ê²°ì¬'\n",
    "        \n",
    "        if not folder_path.exists():\n",
    "            print(f'âš  í´ë” ì—†ìŒ: {folder_path}')\n",
    "            continue\n",
    "        \n",
    "        html_files = list(folder_path.rglob('*.html'))\n",
    "        print(f'ğŸ“ {folder_name} (end_year={end_year}): {len(html_files)}ê°œ íŒŒì¼')\n",
    "        \n",
    "        for html_file in html_files:\n",
    "            source_id = extract_source_id(html_file.name)\n",
    "            if source_id:\n",
    "                html_index[source_id] = (str(html_file), end_year)\n",
    "    \n",
    "    print(f'\\nâœ… ì´ {len(html_index)}ê°œ HTML íŒŒì¼ ì¸ë±ì‹± ì™„ë£Œ')\n",
    "    return html_index\n",
    "\n",
    "# ì¸ë±ìŠ¤ ìƒì„± (ì‹œê°„ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŒ)\n",
    "print('HTML íŒŒì¼ ìŠ¤ìº” ì¤‘...')\n",
    "html_index = build_html_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DBì—ì„œ ë°ì´í„° ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEEJUHWAN\\AppData\\Local\\Temp\\ipykernel_220\\1344481660.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DBì—ì„œ 23320ê±´ ì¡°íšŒ ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜:\n",
      "end_year\n",
      "2010     841\n",
      "2015    6588\n",
      "2020    7705\n",
      "2025    8186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_db_documents():\n",
    "    \"\"\"\n",
    "    DBì—ì„œ ëª¨ë“  ë¬¸ì„œì˜ source_id, end_year, activities ì¡°íšŒ\n",
    "    \"\"\"\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    \n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT source_id, end_year, title, activities\n",
    "        FROM documents\n",
    "        ORDER BY end_year, source_id\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, conn)\n",
    "        print(f'âœ… DBì—ì„œ {len(df)}ê±´ ì¡°íšŒ ì™„ë£Œ')\n",
    "        \n",
    "        # end_yearë³„ í†µê³„\n",
    "        print('\\nğŸ“Š ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜:')\n",
    "        print(df.groupby('end_year').size())\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# DB ì¡°íšŒ\n",
    "db_df = get_db_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëˆ„ë½ ê²€ì¦ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì¦ ì‹œì‘...\n",
      "ì§„í–‰: 500/23320\n",
      "ì§„í–‰: 1000/23320\n",
      "ì§„í–‰: 1500/23320\n",
      "ì§„í–‰: 2000/23320\n",
      "ì§„í–‰: 2500/23320\n",
      "ì§„í–‰: 3000/23320\n",
      "ì§„í–‰: 3500/23320\n",
      "ì§„í–‰: 4000/23320\n",
      "ì§„í–‰: 4500/23320\n",
      "ì§„í–‰: 5000/23320\n",
      "ì§„í–‰: 5500/23320\n",
      "ì§„í–‰: 6000/23320\n",
      "ì§„í–‰: 6500/23320\n",
      "ì§„í–‰: 7000/23320\n",
      "ì§„í–‰: 7500/23320\n",
      "ì§„í–‰: 8000/23320\n",
      "ì§„í–‰: 8500/23320\n",
      "ì§„í–‰: 9000/23320\n",
      "ì§„í–‰: 9500/23320\n",
      "ì§„í–‰: 10000/23320\n",
      "ì§„í–‰: 10500/23320\n",
      "ì§„í–‰: 11000/23320\n",
      "ì§„í–‰: 11500/23320\n",
      "ì§„í–‰: 12000/23320\n",
      "ì§„í–‰: 12500/23320\n",
      "ì§„í–‰: 13000/23320\n",
      "ì§„í–‰: 13500/23320\n",
      "ì§„í–‰: 14000/23320\n",
      "ì§„í–‰: 14500/23320\n",
      "ì§„í–‰: 15000/23320\n",
      "ì§„í–‰: 15500/23320\n",
      "ì§„í–‰: 16000/23320\n",
      "ì§„í–‰: 16500/23320\n",
      "ì§„í–‰: 17000/23320\n",
      "ì§„í–‰: 17500/23320\n",
      "ì§„í–‰: 18000/23320\n",
      "ì§„í–‰: 18500/23320\n",
      "ì§„í–‰: 19000/23320\n",
      "ì§„í–‰: 19500/23320\n",
      "ì§„í–‰: 20000/23320\n",
      "ì§„í–‰: 20500/23320\n",
      "ì§„í–‰: 21000/23320\n",
      "ì§„í–‰: 21500/23320\n",
      "ì§„í–‰: 22000/23320\n",
      "ì§„í–‰: 22500/23320\n",
      "ì§„í–‰: 23000/23320\n",
      "\n",
      "âœ… ê²€ì¦ ì™„ë£Œ!\n",
      "ğŸ”´ ëˆ„ë½ ë°œê²¬: 212ê±´\n"
     ]
    }
   ],
   "source": [
    "def verify_comments(db_df, html_index):\n",
    "    mismatches = []\n",
    "    total = len(db_df)\n",
    "    \n",
    "    for idx, row in db_df.iterrows():\n",
    "        source_id = str(row['source_id'])\n",
    "        end_year = row['end_year']\n",
    "        title = row['title']\n",
    "        \n",
    "        if (idx + 1) % 500 == 0:\n",
    "            print(f'ì§„í–‰: {idx + 1}/{total}')\n",
    "        \n",
    "        if source_id not in html_index:\n",
    "            continue\n",
    "        \n",
    "        html_path, html_end_year = html_index[source_id]\n",
    "        \n",
    "        if html_end_year != end_year:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            db_activities = json.loads(row['activities'], strict=False) if row['activities'] else []\n",
    "        except:\n",
    "            db_activities = []\n",
    "        \n",
    "        # HTML íŒŒì‹±\n",
    "        html_comments, error = parse_html_comments(html_path)\n",
    "        if error or html_comments is None:\n",
    "            continue\n",
    "        \n",
    "        # HTML ì´ë¦„ â†’ ì˜ê²¬ ë§¤í•‘ (ê°™ì€ ì´ë¦„ ì—¬ëŸ¬ ê°œë©´ ë¦¬ìŠ¤íŠ¸ë¡œ)\n",
    "        html_dict = {}\n",
    "        for name, comment in html_comments:\n",
    "            if name not in html_dict:\n",
    "                html_dict[name] = []\n",
    "            html_dict[name].append(comment)\n",
    "        \n",
    "        # DB activities ìˆœíšŒí•˜ë©° ë¹„êµ\n",
    "        name_count = {}  # ê°™ì€ ì´ë¦„ ëª‡ ë²ˆì§¸ì¸ì§€ ì¶”ì \n",
    "        for act in db_activities:\n",
    "            name = act.get('name', '')\n",
    "            db_comment = (act.get('actionComment') or '').strip()\n",
    "            \n",
    "            if not name:\n",
    "                continue\n",
    "            \n",
    "            # ê°™ì€ ì´ë¦„ ëª‡ ë²ˆì§¸ì¸ì§€\n",
    "            if name not in name_count:\n",
    "                name_count[name] = 0\n",
    "            idx_for_name = name_count[name]\n",
    "            name_count[name] += 1\n",
    "            \n",
    "            # HTMLì—ì„œ í•´ë‹¹ ì´ë¦„ì˜ ì˜ê²¬ ì°¾ê¸°\n",
    "            if name in html_dict and idx_for_name < len(html_dict[name]):\n",
    "                html_comment = html_dict[name][idx_for_name].strip()\n",
    "                \n",
    "                # HTMLì— ì˜ê²¬ ìˆê³  DBì— ì—†ìœ¼ë©´ ëˆ„ë½\n",
    "                if html_comment and not db_comment:\n",
    "                    mismatches.append({\n",
    "                        'source_id': source_id,\n",
    "                        'end_year': end_year,\n",
    "                        'title': title,\n",
    "                        'name': name,\n",
    "                        'html_comment': html_comment,\n",
    "                        'db_comment': db_comment,\n",
    "                        'html_path': html_path\n",
    "                    })\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "print('ê²€ì¦ ì‹œì‘...')\n",
    "mismatches = verify_comments(db_df, html_index)\n",
    "print(f'\\nâœ… ê²€ì¦ ì™„ë£Œ!')\n",
    "print(f'ğŸ”´ ëˆ„ë½ ë°œê²¬: {len(mismatches)}ê±´')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "('C:\\\\Users\\\\LEEJUHWAN\\\\Downloads\\\\2011-01-01~2015-12-31\\\\html\\\\ê²°ì¬\\\\2015\\\\20150914_ë°•ë¯¼ì˜ í˜„ëŒ€íŒŒì›Œí… ì¶œì¥ í’ˆì˜_2009078.html', 2015)\n"
     ]
    }
   ],
   "source": [
    "# 1. html_indexì— ìˆëŠ”ì§€ í™•ì¸\n",
    "print('2009078' in html_index)\n",
    "\n",
    "# 2. ìˆë‹¤ë©´ ì •ë³´ í™•ì¸\n",
    "if '2009078' in html_index:\n",
    "    print(html_index['2009078'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_spans ê°œìˆ˜: 1\n",
      "\n",
      "=== user_span 0 ===\n",
      "ì´ë¦„: ë°•ìƒíƒ/ë¶€ì‚¬ì¥/ì „ë¬¸ê°€ê·¸ë£¹\n",
      "\n",
      "í˜•ì œ ìš”ì†Œë“¤:\n",
      "  0: <None> - ë‚´ìš©: '...' \n",
      "  1: <br> - ë‚´ìš©: 'ê²Œì‹œíŒì— ê³µì§€í•œ ì „ê²°ê·œì • ë‚´ìš© ì‚´í´ë³´ì‹œê³  í–¥í›„ë¶€í„°ëŠ”  í’ˆì˜ì‹œ ì „ê²°ê·œì • ì ìš©í•´ì„œ ì²˜ë¦¬í•˜ì„¸ìš”\n",
      "...' \n"
     ]
    }
   ],
   "source": [
    "# ë””ë²„ê¹…: ì‹¤ì œ HTML íŒŒì‹± ê³¼ì • í™•ì¸\n",
    "html_path = html_index['2009078'][0]\n",
    "with open(html_path, 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "opinion_th = soup.find('th', string=lambda s: s and 'ê²°ì¬ì˜ê²¬' in s)\n",
    "opinion_td = opinion_th.find_next_sibling('td')\n",
    "user_spans = opinion_td.find_all('span', class_='user')\n",
    "\n",
    "print(f\"user_spans ê°œìˆ˜: {len(user_spans)}\")\n",
    "\n",
    "for i, user_span in enumerate(user_spans):\n",
    "    print(f\"\\n=== user_span {i} ===\")\n",
    "    name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "    print(f\"ì´ë¦„: {name_elem.get_text(strip=True) if name_elem else 'None'}\")\n",
    "    \n",
    "    print(\"\\ní˜•ì œ ìš”ì†Œë“¤:\")\n",
    "    for j, sibling in enumerate(user_span.next_siblings):\n",
    "        if hasattr(sibling, 'name'):\n",
    "            print(f\"  {j}: <{sibling.name}> - ë‚´ìš©: '{sibling.get_text(strip=True)[:50]}...' \")\n",
    "        else:\n",
    "            text = str(sibling).strip()[:20]\n",
    "            print(f\"  {j}: í…ìŠ¤íŠ¸ë…¸ë“œ - '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "íŒŒì‹± ê²°ê³¼: [('ìœ íƒœê²½', ''), ('ë°•ìƒíƒ', '')]\n"
     ]
    }
   ],
   "source": [
    "# 2008637 í…ŒìŠ¤íŠ¸\n",
    "print('2008637' in html_index)\n",
    "\n",
    "if '2008637' in html_index:\n",
    "    html_path = html_index['2008637'][0]\n",
    "    comments, error = parse_html_comments(html_path)\n",
    "    print(f'íŒŒì‹± ê²°ê³¼: {comments}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_spans ê°œìˆ˜: 2\n",
      "\n",
      "=== user_span 0 ===\n",
      "ì´ë¦„: ìœ íƒœê²½/ê³¼ì¥/(ì£¼)ì• ë‹ˆíŒŒì´ë¸Œ\n",
      "í˜•ì œ ìš”ì†Œë“¤:\n",
      "  1: <br> class=None - í…ìŠ¤íŠ¸: 'ìœ ë¹„ë³´ìˆ˜ ê³„ì•½ì„œìƒì˜ ì„œë¹„ìŠ¤ ë‚´ìš©ì— ëŒ€í•´ ê²€í† ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.ê¸°ì•ˆë°•ìƒíƒ/ë¶€ì‚¬ì¥/ì „ë¬¸'\n",
      "\n",
      "=== user_span 1 ===\n",
      "ì´ë¦„: ë°•ìƒíƒ/ë¶€ì‚¬ì¥/ì „ë¬¸ê°€ê·¸ë£¹\n",
      "í˜•ì œ ìš”ì†Œë“¤:\n",
      "  1: <br> class=None - í…ìŠ¤íŠ¸: 'ì„œë¹„ìŠ¤ ë²”ìœ„ ë° ë³„ì²¨ì˜ ì„œë¹„ìŠ¤ë‚´ìš© ìˆ˜ì •í•´ì£¼ì„¸ìš”..'\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„¸ ë””ë²„ê¹… (ìˆ˜ì •)\n",
    "html_path = html_index['2008637'][0]\n",
    "with open(html_path, 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "opinion_th = soup.find('th', string=lambda s: s and 'ê²°ì¬ì˜ê²¬' in s)\n",
    "opinion_td = opinion_th.find_next_sibling('td')\n",
    "user_spans = opinion_td.find_all('span', class_='user')\n",
    "\n",
    "print(f\"user_spans ê°œìˆ˜: {len(user_spans)}\")\n",
    "\n",
    "for i, user_span in enumerate(user_spans):\n",
    "    print(f\"\\n=== user_span {i} ===\")\n",
    "    name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "    print(f\"ì´ë¦„: {name_elem.get_text(strip=True) if name_elem else 'None'}\")\n",
    "    \n",
    "    print(\"í˜•ì œ ìš”ì†Œë“¤:\")\n",
    "    for j, sibling in enumerate(user_span.next_siblings):\n",
    "        if j > 5:\n",
    "            break\n",
    "        if hasattr(sibling, 'name') and sibling.name:\n",
    "            cls = sibling.get('class') if hasattr(sibling, 'get') else None\n",
    "            print(f\"  {j}: <{sibling.name}> class={cls} - í…ìŠ¤íŠ¸: '{sibling.get_text(strip=True)[:50]}'\")\n",
    "        else:\n",
    "            text = str(sibling).strip()[:30]\n",
    "            if text:\n",
    "                print(f\"  {j}: í…ìŠ¤íŠ¸ë…¸ë“œ - '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë¦„: ìœ íƒœê²½/ê³¼ì¥/(ì£¼)ì• ë‹ˆíŒŒì´ë¸Œ\n",
      "ë‹¤ìŒ div: ìœ ë¹„ë³´ìˆ˜ ê³„ì•½ì„œìƒì˜ ì„œë¹„ìŠ¤ ë‚´ìš©ì— ëŒ€í•´ ê²€í† ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ë¦„: ë°•ìƒíƒ/ë¶€ì‚¬ì¥/ì „ë¬¸ê°€ê·¸ë£¹\n",
      "ë‹¤ìŒ div: ì„œë¹„ìŠ¤ ë²”ìœ„ ë° ë³„ì²¨ì˜ ì„œë¹„ìŠ¤ë‚´ìš© ìˆ˜ì •í•´ì£¼ì„¸ìš”..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lxml í…ŒìŠ¤íŠ¸\n",
    "html_path = html_index['2008637'][0]\n",
    "with open(html_path, 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'lxml')\n",
    "\n",
    "opinion_th = soup.find('th', string=lambda s: s and 'ê²°ì¬ì˜ê²¬' in s)\n",
    "opinion_td = opinion_th.find_next_sibling('td')\n",
    "user_spans = opinion_td.find_all('span', class_='user')\n",
    "\n",
    "for user_span in user_spans:\n",
    "    name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "    print(f\"ì´ë¦„: {name_elem.get_text(strip=True)}\")\n",
    "    \n",
    "    next_div = user_span.find_next('div')\n",
    "    print(f\"ë‹¤ìŒ div: {next_div.get_text(strip=True)[:50] if next_div else 'None'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì—°ë„ë³„ ëˆ„ë½ í˜„í™©:\n",
      "end_year\n",
      "2010     17\n",
      "2015    179\n",
      "2020     16\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š ê²°ì¬ìë³„ ëˆ„ë½ í˜„í™© (ìƒìœ„ 20ëª…):\n",
      "name\n",
      "ì†¡ì¤€ì„     30\n",
      "ì •ì£¼ì—°    15\n",
      "ê¹€ë™ë ¥    12\n",
      "ê¹€ì€ì˜     8\n",
      "ì´í•„í˜¸     7\n",
      "ìœ¤ìƒí˜¸     6\n",
      "ì´ì¢…ìˆ˜     6\n",
      "ë°•ì •ê·      6\n",
      "ìµœê¸°ì›     6\n",
      "ì°¨ì›ì¤€     5\n",
      "ê¹€ê·œì¼     5\n",
      "ê¹€ê´‘í¬     5\n",
      "ê¹€ì„±ìˆ˜     4\n",
      "ê¹€íƒœì •     4\n",
      "ì •ë³‘í˜¸     4\n",
      "ì„í˜„ì¤€     4\n",
      "ì´í˜•ê·      4\n",
      "ì˜¤ì£¼í™˜     4\n",
      "ì–‘ê¸°í›ˆ     4\n",
      "CEO     4\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "ìƒì„¸ ëˆ„ë½ ëª©ë¡ (ì²˜ìŒ 20ê±´):\n",
      "================================================================================\n",
      "\n",
      "[1] source_id: 2002083 (end_year: 2010)\n",
      "    ì œëª©: 2010ë…„ 1ì›” ì”ì—…ì‹ëŒ€ ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    HTML ì˜ê²¬: ì¦ë¹™ì˜ìˆ˜ì¦ì„ ì •ìƒ ì ‘ìˆ˜ë°›ì„ë•Œê¹Œì§€ ë³´ë¥˜í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "ë¹ ë¥¸ì‹œì¼ë‚´ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[2] source_id: 2002085 (end_year: 2010)\n",
      "    ì œëª©: êµ­ë‚´ ì¶œì¥ë¹„ ì‹ ì²­(1/19,22,25 - 3ì¼ KTë³¸ì‚¬)\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    HTML ì˜ê²¬: ì¦ë¹™ì˜ìˆ˜ì¦ì„ ì •ìƒ ì ‘ìˆ˜ë°›ì„ë•Œê¹Œì§€ ë³´ë¥˜í•˜ê² ìŠµë‹ˆë‹¤. \n",
      "ë¹ ë¥¸ì‹œì¼ë‚´ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[3] source_id: 2002100 (end_year: 2010)\n",
      "    ì œëª©: 201001ì›”ë¶„ ì‹ëŒ€ ì‹ ì²­ì…ë‹ˆë‹¤.^^\n",
      "    ê²°ì¬ì: ê¹€ëŒ€í™”\n",
      "    HTML ì˜ê²¬: ì •ì£¼ì—°ëŒ€ë¦¬!\n",
      "\n",
      "11ì›”, 12ì›” ì‹ëŒ€ ì§€ê¸‰ ê±´ í™•ì¸ ìš”ì²­ë“œë¦½ë‹ˆë‹¤.\n",
      "ìŠ¹ì¸ì€ í–ˆì—ˆìŠµë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[4] source_id: 2002147 (end_year: 2010)\n",
      "    ì œëª©: 2ì›” ì•„ì›ƒì†Œì‹± ë¹„ìš© ê²°ì œ í’ˆì˜-ê¸°ìˆ ì—°êµ¬ë¶€ë¬¸\n",
      "    ê²°ì¬ì: CEO\n",
      "    HTML ì˜ê²¬: ìŠ¹ì¸í•©ë‹ˆë‹¤.\n",
      "1. ê·¸ëŸ°ë° í’ˆì˜í•œ ë‚´ìš©ì´  C/Pë‚´ì˜ ê¸ˆì•¡ì…ë‹ˆê¹Œ ?  ì•„ë‹ˆë©´?\n",
      "2. ê²Œì•½ê¸ˆì•¡ì—ì„œ ì”ì—¬ê¸ˆì•¡ì€ ì–¼ë§ˆë‚˜ ë‚¨ì•˜ë‹¤ëŠ” ê²ƒì¸ì§€?\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[5] source_id: 2002298 (end_year: 2010)\n",
      "    ì œëª©: ì°¨ì›ì¤€ ê³¼ì¥ ì…ì‚¬ ì±„ìš©í’ˆì˜ê±´\n",
      "    ê²°ì¬ì: ê¹€ë™ë ¥\n",
      "    HTML ì˜ê²¬: í•©ì˜í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[6] source_id: 2002358 (end_year: 2010)\n",
      "    ì œëª©: ì—°ì°¨íœ´ê°€ í’ˆì˜ ì‹ ì²­_í—ˆì§€í›ˆ\n",
      "    ê²°ì¬ì: í—ˆì§€í›ˆ\n",
      "    HTML ì˜ê²¬: ì›¨ë”©ì´¬ì˜ìœ¼ë¡œ ì¸í•´ íœ´ê°€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[7] source_id: 2002397 (end_year: 2010)\n",
      "    ì œëª©: AnyFive íšŒì‹ë¹„ ì§€ì› ìš”ì²­\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    HTML ì˜ê²¬: ì´ë²ˆê±´ì€ íšŒì‹ë¹„ë¡œ ì²˜ë¦¬í•˜ì§€ ì•Šê² ìŠµë‹ˆë‹¤.\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[8] source_id: 2002570 (end_year: 2010)\n",
      "    ì œëª©: 8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸\n",
      "    ê²°ì¬ì: ì •ì£¼ì—°\n",
      "    HTML ì˜ê²¬: í•©ì˜í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[9] source_id: 2002580 (end_year: 2010)\n",
      "    ì œëª©: ì¬ì§ì¦ëª…ì„œë°œê¸‰ì‹ ì²­ ì˜ ê±´ (ì¥ëª…í›ˆ)\n",
      "    ê²°ì¬ì: ì¥ëª…í›ˆ\n",
      "    HTML ì˜ê²¬: LGì „ì ì—°êµ¬ì†Œ ì¶œì…ì¦ ë°œê¸‰ì— í•„ìš”í•˜ì—¬ ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[10] source_id: 2002628 (end_year: 2010)\n",
      "    ì œëª©: ì¶”ì„ì—°íœ´ ì—°ì°¨íœ´ê°€ ì‚¬ìš© ìš”ì²­\n",
      "    ê²°ì¬ì: ë°•ì •ê· \n",
      "    HTML ì˜ê²¬: ì¦ê±°ìš´ ì¶”ì„ì—°íœ´ë˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[11] source_id: 2002658 (end_year: 2010)\n",
      "    ì œëª©: [LGí™”í•™/ê¸°ìˆ ì—°êµ¬ì›] ì„œìš¸ íŠ¸ìœˆë¹Œë”© ì¶œì¥\n",
      "    ê²°ì¬ì: ì´í•„í˜¸\n",
      "    HTML ì˜ê²¬: LGí™”í•™ ë³¸ì‚¬ (ì„œìš¸ íŠ¸ìœˆë¹Œë”©)ìœ¼ë¡œ ì¶œì¥ì„ ê°€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì €ë… 6ì‹œì¯¤ì— ì¶œì¥ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ì„œ ì§€ê¸ˆì—ì„œì•¼ ì¶œì¥ ì‹ ì²­ì„œë¥¼ ìƒì‹ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ì¬í•˜ì—¬ ì£¼ì‹­ì‹œìš”.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[12] source_id: 2002687 (end_year: 2010)\n",
      "    ì œëª©: 2ì°¨ ë°©ë¬¸]í•˜ì´ë‹‰ìŠ¤ HC ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë¡œì íŠ¸ ê³ ê° ë¯¸íŒ… ì¶œì¥ë¹„ ì‹ ì²­ í’ˆì˜.\n",
      "    ê²°ì¬ì: ê¹€ê·œì¼\n",
      "    HTML ì˜ê²¬: ì´ì‚¬ë‹˜ \n",
      "ê³ ê°ì‚¬ ì‹œìŠ¤í…œ ë¦¬ë·° ë¯¸íŒ… ì¼ì •ìœ¼ë¡œ\n",
      "í•˜ì´ë‹‰ìŠ¤ ì¶”ê°€ ë°©ë¬¸ ì¶œì¥ì„ í’ˆì˜ë“œë¦½ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[13] source_id: 2002722 (end_year: 2010)\n",
      "    ì œëª©: êµ­ë‚´ì¶œì¥ë¹„ ì‹ ì²­ í’ˆì˜ (ì™¸ì£¼ ê¹€í˜„ì£¼ ê³¼ì¥)\n",
      "    ê²°ì¬ì: ê¹€ì„±ìˆ˜\n",
      "    HTML ì˜ê²¬: ì™¸ì£¼ì§ì› ê¹€í˜„ì£¼ ê³¼ì¥ì˜ ëŒ€ì „ ELN ì§€ì›ê±´ì— ëŒ€í•œ êµí†µë¹„ ëŒ€ì‹  ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[14] source_id: 2002760 (end_year: 2010)\n",
      "    ì œëª©: ì•¼ê·¼ì‹ëŒ€(2010ë…„ 10ì›”)\n",
      "    ê²°ì¬ì: ì´ì¢…ìˆ˜\n",
      "    HTML ì˜ê²¬: í”„ë¡œì íŠ¸ ì§€ì› ë° Trouble shooting (íƒ€ ì‹œìŠ¤í…œ error) ì§€ì›/ë³´ê³ ë¡œ ë°œìƒí•œ ì•¼ê·¼ë‚´ì—­ ì…ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[15] source_id: 2002784 (end_year: 2010)\n",
      "    ì œëª©: ì‹ì•½ì²­ ì¶œì¥í’ˆì˜ ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    ê²°ì¬ì: ê¹€í˜„ê¸¸\n",
      "    HTML ì˜ê²¬: ì¶œì¥ë¹„ í’ˆì˜ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[16] source_id: 2002838 (end_year: 2010)\n",
      "    ì œëª©: ë²•ì¸ì¹´ë“œì‚¬ìš©ë‚´ì—­ ì •ì‚°(11ì›”)\n",
      "    ê²°ì¬ì: ê¹€ì€ì˜\n",
      "    HTML ì˜ê²¬: ì˜ìˆ˜ì¦ ì‹¤ë¬¼ì€ ë³¸ì‚¬ ë°©ë¬¸ì‹œ ì „ë‹¬ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[17] source_id: 2002840 (end_year: 2010)\n",
      "    ì œëª©: [ê³„ì•½í’ˆì˜]ìœ ì§€ì„ (í”„ë¦¬ëœì„œ) íˆ¬ì…/ê³„ì•½ í’ˆì˜-LGì „ì G-TIPIS êµ¬ì¶•\n",
      "    ê²°ì¬ì: CEO\n",
      "    HTML ì˜ê²¬: ë³„ë„ ë³´ê³ í•´ ì£¼ì„¸ìš”.\n",
      "ì •ì—°ìˆœì”¨ëŠ” ì™„ì „íˆ ë¹ ì§„ê²ƒì´ ì•„ë‹ˆê³  ëŒ€ì²´ë¼ëŠ” ê²ƒì¸ì§€ ?\n",
      "12ì›”ì€ 0.5ê°€ ì•„ë‹ˆê³  ê¸°ê°„ì´ ì¢€ ê¸¸ë‹¤ë©´. ì„ í–‰í•˜ì—¬ ë³¸ì‚¬ì—ì„œ ë‹¤ë¥¸ì—…ë¬´ 1-2ì£¼ ì§€ì›ì€ ì–´ë ¤ìš´ì§€ ?\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[18] source_id: 2002928 (end_year: 2015)\n",
      "    ì œëª©: ì„œìš¸ ì¶œì¥ ê²½ë¹„ ì‹ ì²­ì˜ ê±´\n",
      "    ê²°ì¬ì: ì´í•„í˜¸\n",
      "    HTML ì˜ê²¬: ì‹œë¬´ì‹ì— ì°¸ì„í•˜ì˜€ë˜ ë¹„ìš©ì„ ì²­êµ¬í•©ë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[19] source_id: 2002952 (end_year: 2015)\n",
      "    ì œëª©: ê°œì¸ì ì¸ ì‚¬ìœ ë¡œ í‡´ì§í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
      "    ê²°ì¬ì: ê¹€ì™•ìˆ˜\n",
      "    HTML ì˜ê²¬: ë¶€ë“ì´í•˜ê²Œ ê°œì¸ì ì¸ ì‚¬ì •ì—ì˜í•´\n",
      "í‡´ì§ì„ ê²°ë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë“¤ê»˜ \n",
      "ì£„ì†¡í•©ë‹ˆë‹¤. \n",
      "2ì›” ë§ê¹Œì§€ ì—…ë¬´ì— ì°¨ì§ˆì´ ì—†ë„ë¡\n",
      "ì² ì €íˆ ì¸ìˆ˜ì¸ê³„í›„ í‡´ì§í•˜ë„ë¡\n",
      "í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n",
      "\n",
      "[20] source_id: 2003062 (end_year: 2015)\n",
      "    ì œëª©: êµìœ¡í›ˆë ¨ ì‹ ì²­ í’ˆì˜\n",
      "    ê²°ì¬ì: ê¹€ì¬ì˜\n",
      "    HTML ì˜ê²¬: êµìœ¡ê¸°ê°„ë‚´ì— ë…¸íŠ¸ë¶ ì§€ì›ì´ í•„ìš”í•©ë‹ˆë‹¤.- ê¹€íƒœì • ìˆ˜ì„ë‹˜ ì°¸ê³ í•´ ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n",
      "    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\n"
     ]
    }
   ],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    print('ğŸ“Š ì—°ë„ë³„ ëˆ„ë½ í˜„í™©:')\n",
    "    print(result_df.groupby('end_year').size())\n",
    "    \n",
    "    print('\\nğŸ“Š ê²°ì¬ìë³„ ëˆ„ë½ í˜„í™© (ìƒìœ„ 20ëª…):')\n",
    "    print(result_df.groupby('name').size().sort_values(ascending=False).head(20))\n",
    "    \n",
    "    # ìƒì„¸ ë‚´ìš© ì¶œë ¥\n",
    "    print('\\n' + '='*80)\n",
    "    print('ìƒì„¸ ëˆ„ë½ ëª©ë¡ (ì²˜ìŒ 20ê±´):')\n",
    "    print('='*80)\n",
    "    \n",
    "    for i, row in result_df.head(20).iterrows():\n",
    "        print(f\"\\n[{i+1}] source_id: {row['source_id']} (end_year: {row['end_year']})\")\n",
    "        print(f\"    ì œëª©: {row['title'][:50]}...\" if len(str(row['title'])) > 50 else f\"    ì œëª©: {row['title']}\")\n",
    "        print(f\"    ê²°ì¬ì: {row['name']}\")\n",
    "        print(f\"    HTML ì˜ê²¬: {row['html_comment'][:100]}...\" if len(row['html_comment']) > 100 else f\"    HTML ì˜ê²¬: {row['html_comment']}\")\n",
    "        print(f\"    DB ì˜ê²¬: (ë¹„ì–´ìˆìŒ)\")\n",
    "else:\n",
    "    print('ğŸ‰ ëˆ„ë½ ì—†ìŒ! ëª¨ë“  ì˜ê²¬ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.')\n",
    "\n",
    "    \"\"\"\n",
    "    24829778 ì„œê°•ì„ê±´ì€ ë¬´ì‹œí•˜ê¸°. ìŠ¹ì¸ ì„œê°•ì„ì´ 2ê°œ (ì‚¬ì´íŠ¸ìƒì—ë„)ìˆìŒìœ¼ë¡œ ìƒê¸°ëŠ” ì˜¤ë¥˜. ë‚´ìš©ì€ ë§ê²Œ ë“¤ì–´ê°. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê²°ê³¼ CSV ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: actionComment_ëˆ„ë½ëª©ë¡_ì¶”ê°€ë¶„.csv\n",
      "   ì´ 212ê±´ì˜ ëˆ„ë½ ë°œê²¬\n"
     ]
    }
   ],
   "source": [
    "if mismatches:\n",
    "    result_df = pd.DataFrame(mismatches)\n",
    "    \n",
    "    output_file = 'actionComment_ëˆ„ë½ëª©ë¡_ì¶”ê°€ë¶„.csv'  # â† ì—¬ê¸° ìˆ˜ì •\n",
    "    result_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f'âœ… ì €ì¥ ì™„ë£Œ: {output_file}')\n",
    "    print(f'   ì´ {len(result_df)}ê±´ì˜ ëˆ„ë½ ë°œê²¬')\n",
    "else:\n",
    "    print('ëˆ„ë½ì´ ì—†ì–´ì„œ CSVë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (ì„ íƒ) ëˆ„ë½ëœ ì˜ê²¬ DB ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 212ê±´ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# âš ï¸ ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ë°±ì—…í•˜ì„¸ìš”!\n",
    "UPDATE_DB = True\n",
    "\n",
    "if UPDATE_DB and mismatches:\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    updated = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for m in mismatches:\n",
    "        source_id = m['source_id']\n",
    "        end_year = m['end_year']\n",
    "        name = m['name']\n",
    "        html_comment = m['html_comment']\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"SELECT activities FROM documents WHERE source_id = %s AND end_year = %s\",\n",
    "            (source_id, end_year)\n",
    "        )\n",
    "        row = cursor.fetchone()\n",
    "        if not row:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # strict=Falseë¡œ ì œì–´ ë¬¸ì í—ˆìš©\n",
    "            activities = json.loads(row[0], strict=False) if row[0] else []\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            print(f'JSON íŒŒì‹± ì˜¤ë¥˜ - source_id: {source_id}, error: {e}')\n",
    "            continue\n",
    "        \n",
    "        modified = False\n",
    "        for act in activities:\n",
    "            if act.get('name') == name and not act.get('actionComment'):\n",
    "                act['actionComment'] = html_comment\n",
    "                modified = True\n",
    "                break\n",
    "        \n",
    "        if modified:\n",
    "            cursor.execute(\n",
    "                \"UPDATE documents SET activities = %s WHERE source_id = %s AND end_year = %s\",\n",
    "                (json.dumps(activities, ensure_ascii=False), source_id, end_year)\n",
    "            )\n",
    "            updated += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f'âœ… {updated}ê±´ ì—…ë°ì´íŠ¸ ì™„ë£Œ')\n",
    "    if error_count:\n",
    "        print(f'âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {error_count}ê±´')\n",
    "else:\n",
    "    print('UPDATE_DB = Trueë¡œ ì„¤ì •í•˜ë©´ ëˆ„ë½ëœ ì˜ê²¬ì´ DBì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== actionComment ì¬ê²€ì¦ ì‹œì‘ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEEJUHWAN\\AppData\\Local\\Temp\\ipykernel_220\\1344481660.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DBì—ì„œ 23320ê±´ ì¡°íšŒ ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜:\n",
      "end_year\n",
      "2010     841\n",
      "2015    6588\n",
      "2020    7705\n",
      "2025    8186\n",
      "dtype: int64\n",
      "ì§„í–‰: 500/23320\n",
      "ì§„í–‰: 1000/23320\n",
      "ì§„í–‰: 1500/23320\n",
      "ì§„í–‰: 2000/23320\n",
      "ì§„í–‰: 2500/23320\n",
      "ì§„í–‰: 3000/23320\n",
      "ì§„í–‰: 3500/23320\n",
      "ì§„í–‰: 4000/23320\n",
      "ì§„í–‰: 4500/23320\n",
      "ì§„í–‰: 5000/23320\n",
      "ì§„í–‰: 5500/23320\n",
      "ì§„í–‰: 6000/23320\n",
      "ì§„í–‰: 6500/23320\n",
      "ì§„í–‰: 7000/23320\n",
      "ì§„í–‰: 7500/23320\n",
      "ì§„í–‰: 8000/23320\n",
      "ì§„í–‰: 8500/23320\n",
      "ì§„í–‰: 9000/23320\n",
      "ì§„í–‰: 9500/23320\n",
      "ì§„í–‰: 10000/23320\n",
      "ì§„í–‰: 10500/23320\n",
      "ì§„í–‰: 11000/23320\n",
      "ì§„í–‰: 11500/23320\n",
      "ì§„í–‰: 12000/23320\n",
      "ì§„í–‰: 12500/23320\n",
      "ì§„í–‰: 13000/23320\n",
      "ì§„í–‰: 13500/23320\n",
      "ì§„í–‰: 14000/23320\n",
      "ì§„í–‰: 14500/23320\n",
      "ì§„í–‰: 15000/23320\n",
      "ì§„í–‰: 15500/23320\n",
      "ì§„í–‰: 16000/23320\n",
      "ì§„í–‰: 16500/23320\n",
      "ì§„í–‰: 17000/23320\n",
      "ì§„í–‰: 17500/23320\n",
      "ì§„í–‰: 18000/23320\n",
      "ì§„í–‰: 18500/23320\n",
      "ì§„í–‰: 19000/23320\n",
      "ì§„í–‰: 19500/23320\n",
      "ì§„í–‰: 20000/23320\n",
      "ì§„í–‰: 20500/23320\n",
      "ì§„í–‰: 21000/23320\n",
      "ì§„í–‰: 21500/23320\n",
      "ì§„í–‰: 22000/23320\n",
      "ì§„í–‰: 22500/23320\n",
      "ì§„í–‰: 23000/23320\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ëˆ„ë½ í•´ê²°ë¨!\n"
     ]
    }
   ],
   "source": [
    "# ì—…ë°ì´íŠ¸ í›„ ì¬ê²€ì¦\n",
    "RECHECK = True\n",
    "\n",
    "if RECHECK:\n",
    "    print('=== actionComment ì¬ê²€ì¦ ì‹œì‘ ===')\n",
    "    \n",
    "    # documents ìƒˆë¡œ ì¡°íšŒ\n",
    "    documents_df_new = get_db_documents()\n",
    "    \n",
    "    # ë‹¤ì‹œ ê²€ì¦\n",
    "    mismatches_new = verify_comments(documents_df_new, html_index)\n",
    "    \n",
    "    if mismatches_new:\n",
    "        print(f'\\nğŸ”´ ì•„ì§ ëˆ„ë½ ë‚¨ìŒ: {len(mismatches_new)}ê±´')\n",
    "        \n",
    "        result_df_new = pd.DataFrame(mismatches_new)\n",
    "        print('\\nì—°ë„ë³„ í˜„í™©:')\n",
    "        print(result_df_new.groupby('end_year').size())\n",
    "    else:\n",
    "        print('\\nğŸ‰ ëª¨ë“  ëˆ„ë½ í•´ê²°ë¨!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
